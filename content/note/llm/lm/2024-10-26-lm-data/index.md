---
title: 语言模型数据
author: wangzf
date: '2024-10-26'
slug: lm-data
categories:
  - nlp
  - deeplearning
tags:
  - model
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
img {
    pointer-events: none;
}
</style>

<details><summary>目录</summary><p>

- [大语言模型背后的数据](#大语言模型背后的数据)
    - [WebText 和 OpenWebText](#webtext-和-openwebtext)
    - [Colossal Clean Crawled Corpus](#colossal-clean-crawled-corpus)
    - [Benchmark 的数据污染问题](#benchmark-的数据污染问题)
    - [GPT-3 的数据集](#gpt-3-的数据集)
    - [The Pile 数据集](#the-pile-数据集)
- [数据集文档](#数据集文档)
- [数据生态](#数据生态)
</p></details><p></p>

任何机器学习方法的起点都是训练数据。通常在机器学习中，
训练数据和测试（评估）数据是相似的，或者至少是同一类型的。
但对于大型语言模型来说，训练数据就是 **“原始文本”**。

# 大语言模型背后的数据

大型语言模型是在 **“原始文本”** 上进行训练的。为了实现高度的能力（如语言能力和世界知识），
这些文本应涵盖广泛的领域、类型、语言等。

网络是寻找这种文本的自然场所（但不是唯一场所），因此这将是主要关注的焦点。
网络的体量绝对巨大，作为下限，谷歌的搜索索引就有 100PB（参考资料）。
实际的网络可能更大，而深网(指的是所有无法被搜索引擎识别的网页)的规模比这还要大。
值得注意的是，大公司中存储的私有数据集甚至比公开可用的数据更大。
例如，沃尔玛每小时就会产生 2.5PB 的数据。

[Common Crawl]() 是一个非营利组织，它对网络进行爬取，并提供免费给公众的快照。
由于其便利性，它已经成为许多模型如 T5、GPT-3 和 Gopher 的标准数据源。
例如，Common Crawl 在 2021 年 4 月的快照就有 320TB 的数据，
这比谷歌的索引小了好几个数量级。

尽管网络数据丰富，但 Bender 等人在 2021 年的研究中指出：

* 大规模数据在全球人口中的代表性仍然不均衡；
    * 网络数据过多地代表了来自发达国家的年轻用户；
    * GPT-2 的训练数据基于 Reddit，根据皮尤互联网研究的 2016 年调查，
      美国 Reddit 用户中有 67% 是男性，64% 的年龄在 18 到 29 岁之间；
    * 维基百科的编者中只有 8.8-15% 是女性；
    * 网络上的骚扰可能会让某些人群（如跨性别者、神经发育不同的人）产生排斥感；
    * 过滤"不良词汇"可能进一步边缘化某些人群（如 LGBT+）；
* 因此，结论是：**理解和记录用于训练大型语言模型的数据集的组成是至关重要的**。

## WebText 和 OpenWebText

[**WebText 数据集**]() 被用于训练 **GPT-2 模型**。其目标是获取既多样化又高质量的数据集。
以前的研究主要是在新闻、维基百科或小说等数据集上进行训练，
而 Common Crawl 包含了大量的垃圾信息（如无意义文本和模板文本）。
Trinh 和 Le 在 2018 年根据 N-Gram 与目标任务的重叠性，
选择了 Common Crawl 的一小部分。
创建 WebText 的过程包括：抓取至少获得 3 个赞的所有外链，
过滤掉维基百科以便在基于维基百科的基准测试中进行评估，最终得到了 40GB 的文本。

尽管 OpenAI 并没有公开发布 WebText 数据集，
但 [**OpenWebText 数据集**](https://skylion007.github.io/OpenWebTextCorpus/) 在理念上复制了 WebText 的构建方法。
也就是说，虽然 OpenWebText 并非 OpenAI 直接发布的 WebText 的副本，
但它遵循了 WebText 的制作思路和方法，目的是尽可能地模拟和复现 WebText 的数据特性和结构。
这样，研究者们就可以利用 OpenWebText 来进行一些原本需要 WebText 数据集的实验和研究。
OpenWebText 从 Reddit 提交的数据集中提取所有 URL，使用 Facebook 的 `fastText` 过滤掉非英语内容，
删除近乎重复的内容，最终得到了 38GB 的文本。

在 2020 年的 RealToxicityPrompts 研究中，Gehman 等人对这两个数据集进行了**毒性分析**：
OpenWebText 有 2.1% 的内容毒性得分 >=50%，WebText 有 4.3% 的内容毒性得分 >=50%。
新闻的可靠性与毒性负相关（Spearman `$\rho=-0.35$`5），
并且 OpenWebText 中有 3% 的内容来自被禁止或被隔离的 subreddits，
如 `/r/The_Donald` 和 `/r/WhiteRights`。

## Colossal Clean Crawled Corpus

> C4

[C4 语料库](https://www.tensorflow.org/datasets/catalog/c4)被用来训练 T5 模型。
这个语料库从 2019 年 4 月的 Common Crawl 快照（1.4 万亿个标记）开始，
移除了 [“bad words”](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/en)，移除了代码（`"{"`），通过 `langdetect` 过滤掉了非英语文本，
最终得到了 806GB 的文本（1560 亿个标记）。

Dodge 等人在 2021 年对 C4 数据集进行了深入分析。分析主要涉及以下几个方面：

* 元数据：来源，话语数据。
* 包含的数据：由机器或人类创作的，社会偏见，数据污染。
* 排除的数据：医疗或健康数据，人口身份。 

值得注意的是，Raffel 等人在 2020 年的研究中只提供了重建脚本；仅运行这些脚本就需要数千美元。
而且，令人惊讶的是，大量数据来自 patents.google.com。互联网档案中的 65% 页面都被纳入其中，
而在这些页面中，92% 的页面是在过去十年内编写的。然而，虽然美国托管的页面占到了 51.3%，
来自印度的页面数量却相对较少，尽管那里有大量的英语使用者。
另外，来自 patents.google.com 的一些文本是自动生成的，
因此可能存在系统性的错误：例如，用外国的官方语言（如日语）提交的专利将自动翻译成英语；
另一些则是由光学字符识别（OCR）自动生成的。

## Benchmark 的数据污染问题

当评估大型语言模型的能力时，常常会使用一些基准数据，例如 **问题-答案对**。
然而，若基准数据在模型的训练数据中出现过，基准性能就可能会产生偏差。
一般而言，在机器学习中，保证训练数据和测试数据的分离（称之为数据卫生）相对容易。
但对于大型语言模型，训练数据和基准数据都源自互联网，要事先保证它们的完全分离就显得有些困难。

以 XSum 摘要数据集为例，输入的是一段关于一个前阿森纳门将的介绍，
而输出则是这位门将被任命为技术主管的新闻，细节如下面的例子。
这就存在两种类型的污染。一种是输入和输出污染，即输入和输出都出现在训练数据中，
其比例在 1.87% 至 24.88% 之间。另一种是只有输入在训练数据中出现，
比如来自维基百科的 QNLI 数据集，这种污染的比例在 1.8% 至 53.6% 之间。

此外，我们还要注意，这种数据污染并不是由于数据集的托管方式导致的，
因为数据集通常会以 JSON 文件的形式存储，而不是网页。
因此也可以说当前的数据污染是一种自身很难避免的特性。

但是，数据集也可能引发多种问题。

* 首先，存在代表性损害的可能，例如，我们发现与特定族群相关的词汇，
  如 `"犹太"` 和 `"阿拉伯"` 与积极情绪词汇的共现频率存在差异，
  这可能反映了模型的某种偏见。
* 其次，数据集的选择和过滤也可能导致分配损害。以过滤版的 Common Crawl（即 C4）为例，
  只有大约 10% 的内容被保留。然而，涉及性取向的内容更容易被过滤掉，
  而其中一部分是并无冒犯之意的。某些特定的方言也更容易被过滤，
  例如非洲裔美国人的英语和西班牙裔的英语，相比之下，白人美国英语的过滤率就要低得多。

## GPT-3 的数据集

GPT-3 的数据集主要源自 Common Crawl，而 Common Crawl 又类似于一个参考数据集——WebText。
GPT-3 下载了 41 个分片的 Common Crawl 数据（2016-2019 年）。
通过训练一个二元分类器来预测 WebText 与 Common Crawl 的区别，
如果分类器认为文档更接近 WebText，那么这个文档就有更大的概率被保留。
在处理数据时，GPT-3 采用了模糊去重的方法（检测 13-Gram 重叠，
如果在少于 10 个训练文档中出现，则移除窗口或文档），并从基准数据集中移除了数据。
此外，GPT-3 也扩大了数据来源的多样性（包括 WebText2、Books1、Books2 以及维基百科）。
在训练过程中，Common Crawl 被降采样，它在数据集中占 82%，但只贡献了60% 的数据。

然而，GPT-3 也暗示了我们除了网络爬虫之外，也许还可以寻找其他更高质量的数据来源。
EleutherAI（一个致力于构建开放语言模型的非营利组织）进一步推动了这个想法。
他们发布了一种语言模型的数据集，名为 The Pile，
其核心理念是从较小的高质量数据源（如学术和专业资源）中获取数据。

## The Pile 数据集

[The Pile 数据集](https://arxiv.org/pdf/2101.00027)包含了 825GB 的英文文本，由 22 个高质量数据集组成。
当用这个数据集训练 GPT-2 Pile（1.5B参数）并与用 GPT-3 数据集训练的 GPT-3（175B 参数）进行比较时，
研究者们发现，The Pile 包含了大量 GPT-3 数据集未能很好覆盖的信息。
他们还分析了贬损内容、性别/宗教偏见等问题，结果与以前的研究大致相同。

总的来说，网络和私有数据的总量是巨大的，
但是简单地将所有数据（甚至是 Common Crawl）都用于训练并不能有效地利用计算资源。
数据的过滤和策划（如 OpenWebText，C4，GPT-3 数据集）是必要的，但可能会导致偏见。
策划非网络的高质量数据集（如 The Pile）是有前途的，但也需要仔细记录和审查这些数据集。

# 数据集文档

深入探讨数据的一般原则，暂时不讨论语言模型数据集的具体内容。

长期以来，人们都明白文档记录的重要性，然而在机器学习领域，这个过程往往被处理得较为随意。
为了更好地理解这一点，让我们来看一些其他领域的例子：在电子行业中，每个组件都有一份详细的数据表，
包含其运行特性、测试结果、推荐使用情况等信息；又如美国食品药品监督管理局要求所有的食品都必须标注营养成分。
Gebru 等人在 2018 年发表的论文深刻影响了这一领域，他们提出了围绕文档的社区规范。
Bender 和 Friedman 在2018年的论文《数据声明》也提出了一个更适用于语言数据集的框架，
这两个工作都在强调透明度。

数据文档的主要目的有两个：

* 一方面，它让数据集的创建者有机会反思他们的决策，以及在创建数据集过程中可能产生的潜在危害，比如社会偏见；
* 另一方面，它让数据集的使用者了解何时可以使用数据集，何时不应使用数据集。

在整个数据集的生命周期中，我们需要考虑很多问题，比如数据集的创建动机，谁是数据集的创建者，
数据集的创建是由谁资助的。

* 在数据集的组成部分，我们需要了解数据集中的实例代表什么，是否有缺失信息，是否包含机密数据等。
* 在收集过程中，我们需要了解每个实例的数据是如何获取的，谁参与了数据收集，
  他们是如何获得报酬的，以及是否进行了道德审查等。
* 在预处理、清理和标记阶段，我们需要了解这些工作是否已经完成，是否有相应的软件可供使用。
* 在数据集的使用方面，我们需要了解数据集是否已经被用于某些任务，是否有不适合使用该数据集的任务。
* 在分发阶段，我们需要了解数据集将如何分发，是否有第三方对数据施加了知识产权或其他的限制。
* 在维护阶段，我们需要了解谁会负责维护数据集，数据集是否会更新。

专门针对自然语言处理（NLP）数据集的工作，比如数据声明，还涵盖了其他方面，
例如策划理念，语言多样性，说话人和注释者的人口统计学信息等。
以 "The Pile" 数据集为例，我们可以更好地理解这些问题。

# 数据生态

目前为止，我们主要关注了现有大型语言模型数据集的分析以及文档记录，
但实际上数据是一个广泛的概念，可以从许多其他角度进行研究。

在数据管理方面，我们在机器学习研究中通常认为数据集是固定的对象，收集起来之后，直接投入到训练算法中。
然而在数据库领域，有一整个子领域正在思考数据是如何产生和使用的生态系统，这在工业领域特别相关。

在基础模型报告的数据部分中讨论了一些问题。

数据治理主要关注一个组织如何创建数据、维护其质量和安全性。
Hugging Face 发起的 BigScience 项目旨在收集一个大型多语种数据集并训练一个大型语言模型。
BigScience 的数据治理工作组正在开发一个框架，以负责任地策划高质量的数据源，而不是无差别地爬取网页。

数据尊严是一个源自微软和 RadicalxChange 的概念，试图思考数据的本质。
人们创造数据，由于人们生活在社会环境中，数据也并不仅仅是个体的财产，而是群体的财产。
比如电子邮件、遗传数据。在个体层面上，数据没有价值，但在集体层面上，它具有巨大的价值。
相关的有一个为在机器学习的背景下给定数据点赋予价值的框架 Data Shapley。
现状是，人们免费放弃他们的数据，大公司从中获取大量的价值和权力。
例如，Alice 和 Bob 都是作家。Alice 免费提供写作示例，这可以被用来训练可以替代 Bob 的语言模型。
我们应该将数据视为劳动而不是财产权。数据隐私是在个人层面上工作，而这是不够的。
有一种提议是数据联盟，这些联盟是介于数据生产者和数据购买者之间的中间组织，
它们能够代表数据生产者进行集体谈判。
