---
title: 大语言模型
subtitle: Large Language Models
list_pages: true
# order_by: title
---

## 大语言模型的学习路径

1. 试用不同的大语言模型(LLM)
    - OpenAI GPT-3.5, GPT-4.0, GPT-4o
    - Meta LlaMA 3.1-8B-Instruct
2. 创建一个 AI 智能体(Agent)
3. 了解目前 LLM 和 AI 的局限性
4. 创建一个简单的 RAG 系统
5. 微调一个 LLM
    - LoRA
6. 应用开发
    - 基于 Linux/Windows 平台的开源 LLM 环境配置指南，针对不同模型要求提供不同的详细环境配置步骤；
    - 国内外主流开源 LLM 的部署使用教程，包括 LLaMA、ChatGLM、InternLM 等；
    - 开源 LLM 的部署应用指导，包括命令行调用、在线 Demo 部署(StreamLit)、LangChain 框架集成等；
    - 开源 LLM 的全量微调、高效微调方法，包括分布式全量微调、LoRA、ptuning 等。

## TODO

* Datawhale
    - [《ChatGPT 原理与应用开发》](https://github.com/datawhalechina/hugging-llm)
    - [开源大模型食用指南](https://github.com/datawhalechina/self-llm/tree/master)
    - [动手学大模型应用开发](https://github.com/datawhalechina/llm-universe)
    - [大模型基础](https://github.com/datawhalechina/so-large-lm)
    - [RAG：GLM-4 代码](https://github.com/datawhalechina/self-llm/tree/master/GLM-4)
* [funNLP GitHub](https://github.com/fighting41love/funNLP)
* [自然语言处理入门练习任务](https://github.com/FudanNLP/nlp-beginner)

## 文档
