---
title: 大语言模型
subtitle: Large Language Models
list_pages: true
# order_by: title
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
img {
    pointer-events: none;
}
</style>

<details><summary>目录</summary><p>

- [学习路径](#学习路径)
- [教程](#教程)
- [文档](#文档)
</p></details><p></p>

## 学习路径

1. 试用不同的大语言模型(LLM)
    - OpenAI GPT-3.5, GPT-4.0, GPT-4o
    - Meta LlaMA 3.1-8B-Instruct
2. 创建一个 AI 智能体(Agent)
3. 了解目前 LLM 和 AI 的局限性
4. 创建一个简单的 RAG 系统
5. 微调一个 LLM
    - LoRA
6. 应用开发
    - 基于 Linux/Windows 平台的开源 LLM 环境配置指南，针对不同模型要求提供不同的详细环境配置步骤；
    - 国内外主流开源 LLM 的部署使用教程，包括 LLaMA、ChatGLM、InternLM 等；
    - 开源 LLM 的部署应用指导，包括命令行调用、在线 Demo 部署(StreamLit)、LangChain 框架集成等；
    - 开源 LLM 的全量微调、高效微调方法，包括分布式全量微调、LoRA、ptuning 等。

## 教程 

* Datawhale
    - [理论：《ChatGPT 原理与应用开发》](https://github.com/datawhalechina/hugging-llm)
    - [理论：大模型基础](https://github.com/datawhalechina/so-large-lm)
    - [实践：开源大模型食用指南](https://github.com/datawhalechina/self-llm)
    - [实践：动手学大模型应用开发](https://github.com/datawhalechina/llm-universe)
    - [实践：大模型白盒子构建指南](https://github.com/datawhalechina/tiny-universe)
* [funNLP GitHub](https://github.com/fighting41love/funNLP)
* [自然语言处理入门练习任务](https://github.com/FudanNLP/nlp-beginner)

## 文档
