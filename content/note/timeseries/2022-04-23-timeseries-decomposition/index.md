---
title: 时间序列分解
author: 王哲峰
date: '2022-04-23'
slug: timeseries-decomposition
categories:
  - timeseries
tags:
  - ml
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
</style>

<details><summary>目录</summary><p>

- [时间序列分解模型](#时间序列分解模型)
  - [加法模型](#加法模型)
  - [乘法模型](#乘法模型)
  - [加法乘法混合模型](#加法乘法混合模型)
- [时间序列的分解方法](#时间序列的分解方法)
  - [使用移动平均法分离出显性的周期性波动](#使用移动平均法分离出显性的周期性波动)
  - [将业务周期性波动效应和随机波动进行分解](#将业务周期性波动效应和随机波动进行分解)
  - [观察数据波动的拐点将时间序列分段](#观察数据波动的拐点将时间序列分段)
  - [利用线性回归基于移动平均数计算长期趋势](#利用线性回归基于移动平均数计算长期趋势)
  - [分离出循环效应和随机波动](#分离出循环效应和随机波动)
  - [检验时间序列分解的效果](#检验时间序列分解的效果)
- [时间序列分解方法的应用局限性](#时间序列分解方法的应用局限性)
  - [时间序列分解模型](#时间序列分解模型-1)
  - [时间序列的长期趋势分析](#时间序列的长期趋势分析)
  - [时间序列季节变动分析](#时间序列季节变动分析)
  - [时间序列循环变动分析](#时间序列循环变动分析)
  - [时间序列不规则变动分析](#时间序列不规则变动分析)
- [时间序列周期性检测](#时间序列周期性检测)
  - [周期性检测简介](#周期性检测简介)
  - [傅里叶变换](#傅里叶变换)
  - [自相关系数](#自相关系数)
  - [周期性检测流程](#周期性检测流程)
    - [检测流程](#检测流程)
    - [实例分析](#实例分析)
  - [周期性检测实践](#周期性检测实践)
- [时间序列季节性检测](#时间序列季节性检测)
  - [傅里叶变换](#傅里叶变换-1)
- [时间序列平稳性检验](#时间序列平稳性检验)
  - [时间序列平稳性](#时间序列平稳性)
    - [时间序列平稳性定义](#时间序列平稳性定义)
      - [严平稳](#严平稳)
      - [宽平稳](#宽平稳)
      - [严平稳与宽平稳的关系](#严平稳与宽平稳的关系)
    - [平稳时间序列](#平稳时间序列)
      - [白噪声](#白噪声)
      - [非白噪声](#非白噪声)
  - [时间序列平稳性检验](#时间序列平稳性检验-1)
  - [时间序列平稳性准换](#时间序列平稳性准换)
- [时间序列趋势性检测](#时间序列趋势性检测)
  - [移动平均](#移动平均)
- [参考](#参考)
</p></details><p></p>

# 时间序列分解模型

时间序列数据，即数据指标按时间维度统计形成的序列。这种数据在我们的日常报表中非常常见。
观察这类数据的出发点有两个：

* 一是长期追踪，一旦指标出现上涨和下跌，能直观地观察到，进而去调查原因
* 二是判断趋势，通过指标的波动，判断指标在未来的走势
  
第一点相对简单，看到指标变化后从不同维度不断下钻，总能找到原因。
第二点则要从时间序列的波动中看出门道，不是光盯着数据看就可以的，
最常见的逻辑就是 “将时间序列波动的信息进行分解”

在时间序列分析中, 常见的分析方法叫做时间序列的分解(Decomposition of Time Series)。
通过分解，将数据分解成可预测部分和不规则变动(随机波动)部分，
可预测部分占比比不规则变动大很多，那么就具备了预测未来的条件

时间序列分解的原理是将时间序列 `$Y_{t}$` 分为三个或四个部分:

`$$Y_{t} = f(T_{t}, S_{t}, C_{t}, I_{t})$$`

* 长期趋势因素(Secular trend) `$T_{t}$`
    - 数据中对时间的变化相对稳定的一部分因素。往往是长期稳定的上涨或下跌。
      这个数据一般可以通过移动平均或者线性回归等方法进行拟合，因此它是可预测的部分
* 季节/周期变动因素(Seasonal Variation) `$S_{t}$`
    - 传统的时间序列分解方法一般用在长期的宏观经济指标中，因此颗粒度是季度，所以会呈季节性变动。
      在数据运营的场景中，季节数据跨度太长，几乎没有使用的必要性。
      所以将季节变动引申为“周期性波动”，而且是显性的周期性波动，
      例如业务指标在一周内会有周末和工作日的差别，在一个月中会有月初和月末的差别。
      周期性波动因素取决于数据处在周期中的位置，通过固定位置的历史数据(取均值或者其他数学变换)，
      也能对未来的某个位置的周期性因素进行估计，因此它也是可预测的部分
* 循环变动因素(Cyclical Variation) `$C_{t}$`
    - 循环变动和季节变动其实很像，也有周期性因素在。但循环变动的周期是隐性的，
      往往要先将显性的周期性波动排除后，再观察剩下的数据部分是否有循环波动的因素，
      若有，也能通过同比计算等方法将其提出，因此也是可预测的
* 随机变动因素(Irregular Variation) `$I_{t}$`
    - 既然是随机波动，自然是不可预测的
    - 时间序列分解的成功与否，取决于两个因素：一是数据序列本身是隐藏着规律的，不可预测的部分只是其中的一小部分；
      二是分解的方法要合适，尤其是周期的判断要准确。因此，这个方法非常考验使用者的经验和直觉

时间序列分解法试图从时间序列中区分出这四种潜在的因素, 特别是长期趋势因素(T)、季节变动因素(S)、
周期性因素(C). 显然, 并非每一个预测对象中都存在着 T、S、C 这三种趋势, 可能是其中的一种或两种. 
一个具体的时间序列究竟由哪几类变动组合, 采取哪种组合形式, 应根据所掌握的资料、时间序列及研究目的来确定

## 加法模型
   
`$$Y_{t} = T_{t} + S_{t} + C_{t} + I_{t}$$`

其中: 

* `$Y_{t}, T_{t}, S_{t}, C_{t}, I_{t}$` 均有相同的量纲
* `$\sum_{t=1}^{k}S_{t}=0$`，`$k$` 为季节性周期长度
* `$I_{t}$` 是独立随机变量序列，服从正态分布

加法模型中的四种成分之间是相互独立的, 某种成分的变动不影响其他成分的变动. 
各个成分都用绝对量表示, 并且具有相同的量纲

## 乘法模型

`$$Y_{t} = T_{t} \times S_{t} \times C_{t} \times I_{t}$$`

其中:

* `$Y_{t}$`，`$T_{t}$` 有相同的量纲
* `$S_{t}$` 为季节性指数，`$C_{t}$` 为循环指数，两者皆为比例数
* `$\sum_{t=1}^{k}S_{t}=k$`，`$k$` 为季节性周期长度
* `$I_{t}$` 是独立随机变量序列，服从正态分布

乘法模型中四种成分之间保持着相互依存的关系, 一般, 长期趋势用绝对量表示, 
具有和时间序列本身相同的量纲, 其他成分则用相对量表示

上面的乘法模型等价于:

`$$\ln y_{t} = \ln S_t + \ln T_t + \ln C_t + \ln I_{t}$$`

由于上面的等价关系, 所以, 有的时候在预测模型的时候会先取对数, 
然后再进行时间序列的分解, 就能得到乘法的形式

## 加法乘法混合模型

`$$Y_{t} = T_{t} \times S_{t} \times C_{t} + I_{t}$$`

其中: 

* `$Y_{t}, T_{t}, C_{t}, I_{t}$` 有相同的量纲，`$S_{t}$` 是季节指数，为比例数
* `$\sum_{t=1}^{k}S_{t} = k$`，`$k$` 为季节性周期长度
* `$I_{t}$` 是独立随机变量序列，服从正态分布

# 时间序列的分解方法

时间序列数据的预测值就是:

长期趋势(线性回归估计值) + 循环效应(循环周期各位置的均值) + 周期效应(业务周期各位置的均值)

就意味着，能通过时间长度和所在周期的位置给出一个未知时间点的预测值

## 使用移动平均法分离出显性的周期性波动

* 首先，清洗数据，将异常值剔除
* 其次，根据现实业务周期(显性周期)，按周期的长度求移动平均数，
  这样所获得的移动平均数就是排除了周期性波动影响和一部分随机波动的数据(`$SI_{1}$`)，
  即移动平均数为长期趋势、循环波动和一部分随机波动(`$TCI_{2}$`)
* 最后，用原始数据减去移动平均数(`$TCI_{2}$`)，就得到了周期性波动效应和一部分随机波动(`$SI_{1}$`)

## 将业务周期性波动效应和随机波动进行分解

这部分的处理取决于周效应和不规则变动的量级。在实际场景中，若量比较大，建议计算每周中对应某一天的均值，
即得到周一的均值、周二的均值等，这便是加法模型中的周效应

`$S = SI_{1} / I_{1}$`

## 观察数据波动的拐点将时间序列分段

移动平均数包含了数据的长期趋势(`$T$`)、循环变动(`$C$`)

* 首先，长期趋势是会改变的，这种改变往往是运营策略的变化带来的，所以不能教条地假设长期趋势稳定不变
* 其次，在数据的不同阶段，循环的周期也会有所不同

## 利用线性回归基于移动平均数计算长期趋势

原始数据在剔除了业务周期波动和随机波动后(`$SI_{1}$`)，剩下了长期趋势和循环变动(`$TC$`)

长期趋势与时间的增加是有关系的(建模的原始假设)，因此以时间为自变量(`$t$`)(起点为0，之后每天都以1自增的序列)，
以业务周期移动平均数(`$TC$`)为因变量，构建一个线性回归模型。
由时间(`$t$`)和回归模型计算得出的因变量(`$TC$`)的估计值，就是长期趋势 `$T$`，用移动平均数减去 `$T$`，
剩下的部分就是循环效应和一部分的随机波动(不规则变动)。

需要注意的是，估计长期趋势(趋势拟合的方法)并不是只能采用线性回归。
这取决于数据点的分布，有时要用指数回归，有时要用多项式回归。
而且，在数据的不同阶段，使用的长期趋势估计方式也可以是不同的

## 分离出循环效应和随机波动

因为循环效应不是那么容易观察出来的。一个简单的观察办法是：看数据是否有规律地分布在 0 值之上和 0 值之下。
若数据不规则地在 0 值上下跳动，则可以认定这是随机波动，不需要分离循环效应。
若数据一段时间在 0 之上，一段时间在 0 之下，且持续的时间大致相同，那么就有必要分离循环效应

一个波峰加一个波谷所跨越的时间，就是循环的周期(这个规则适用于所有周期性数据的判断)。
计算循环中各个位置的均值，即为循环效应

移动平均数(`$TCI_{2}$`)与线性回归值(`$T$`)的差值，即“循环效应+不规则变动”(`$CI_{2}$`)，
减去循环效应(`$C$`)后(除了阶段2，其他阶段的循环效应认为是0)，
剩下的就是随机波动(`$I_{2}$`)

## 检验时间序列分解的效果

* 第一种手段就是图形法，观察预测值与实际值的契合程度
* 第二种方法是回归分析法
    - 以预测值为自变量，实际值为因变量，建立一个线性回归模型，
      观察模型的拟合优度，通过拟合优度判断预测是否靠谱

# 时间序列分解方法的应用局限性

每种分析方法都有它的局限性，时间序列分解方法也一样，“分解”这种思维，事实上是可以应用在更广泛的业务分析中的，
而不仅是时间序列数据。通过以上案例，需要注意时间序列分解法中的以下几点局限性

1. 原始数据中的随机波动因素占比不能过大
    - 随机波动因素的占比过大，说明我们不可预测的东西过多，那么，剩余的部分再怎么分解也无济于事
2. 分解的过程中，确定移动平均的期数、数据阶段的划分、趋势拟合的方法、循环周期都带有一定的主观判断。
   这就对分析者提出了较高的要求。在应用时，需要不断地改变这些参数来获得更好的结果。而且，经常会出现仁者见仁的局面
3. 用加法模型、乘法模型或混合模型没有定论，需要具体问题具体分析。实际情况中，往往是混合模型用得比较多
4. 需要用在长期的数据序列中。时间序列的分解对时间的长度是有要求的，却没有明确的阈值
    - 至少要在 40 个数据点以上才能讨论所谓的长期趋势。另外，该方法不适合用在比“天”的颗粒度更小的时间维度上
5. 时间序列阶段的改变可预测性较差
    - 将时间序列分解的结果应用于预测时，是不知道何时进入新的阶段的(序列的结构性断点不可预测)。
      今天还在阶段1，明天就进入阶段2了，这可如何是好？有一些缓解这个问题的方法：
        - 一是做“事后诸葛亮”，即连续追踪数据，若连续出现上涨或者下跌，或者出现“史无前例”的最大值和最小值，
          那么就要考虑数据的结构性变化可能出现了，就要放弃原先的建模方式；
        - 二是从业务决策上“明察秋毫”，数据出现结构性变化，往往是较大的决策改变或者产品迭代引起的，
          那么反过来思考，若业务出现一些“重大改变”，也许就应该重新建模了。
6. 真正的预测，只能在阶段内进行
    - 在本例中能预测未来数据的其实也就只有阶段4。但也不用慌，历史往往会重演。
      前面三个阶段的数据特征，一定会出现在未来的某个时间点。
      所以，当数据进入有“历史参考”的某个阶段时，可以用历史经验预测未来的走势


时间序列分解法是数年来一直非常有用的方法，一个时间序列往往是一下几类变化形式的叠加或耦合：

* 长期趋势(Secular trend, T)：长期趋势指现象在较长时期内持续发展变化的一种趋向或状态。
* 季节变动(Seasonal Variation, S)：季节波动是由于季节的变化引起的现象发展水平的规则变动
* 循环波动(Cyclical Variation, C)：循环波动指以若干年为期限，不具严格规则的周期性连续变动
* 不规则波动(Irregular Variation, I): 不规则波动指由于众多偶然因素对时间序列造成的影响

## 时间序列分解模型

* 加法模型
* 乘法模型
* 加乘混合模型

## 时间序列的长期趋势分析

* 移动平均法
    - 在原时间序列内依次求连续若干期的平均数作为其某一期的趋势值，
      如此逐项递移求得一系列的移动平均数，形成一个平均数时间序列
* 时间回归法
    - 使用回归分析中的最小二乘法，以时间 `$t$` 或 `$t$` 的函数为自变量拟合趋势方程。常用的趋势方程如下
        - 一阶线性方程
        - 二次、多次方程曲线
        - 指数曲线

## 时间序列季节变动分析


## 时间序列循环变动分析


## 时间序列不规则变动分析




# 时间序列周期性检测

分析序列中的周期性或准周期序列(如季节、星期等), 可通过直观比较得到周期性的定性结果:
    
- 周期序列的功率谱会产生尖峰
- 自相关系数是连续振荡波形
- 数据的概率密度直方图是下凸, 非周期是上凸

## 周期性检测简介

任何事物在两个不同时刻都不可能保持完全相同的状态, 但很多变化往往存在着一定的规律, 
例如 24 小时日出日落, 潮起潮落, 这些现象通常称为周期.

周期性指时间序列中呈现出来的围绕长期趋势的一种波浪形或震荡式变动. 准确提取周期信息, 
不仅能反映当前数据的规律, 应用于相关场景, 还可以预测未来数据变化趋势. 
这是时间序列研究的基本要素.通过肉眼观察时序图, 可以很容易地判断数据是否满足周期性, 
但无法知道准确的周期时长, 且当数据组数达到一定数量时, 这种方式就不再适用了.

一般而言, 时间序列周期性分为三种: 

- 符号性周期: 表示只有一个以上的符号是周期性的, 并且部分地出现
    - 例如序列 `f` bcn `f` kgb `f` ops 中的 `f` 有周期性, 它的周期是 4, 可以用 CONV 方法检测
- 部分周期性: 表示有一个以上的符号是周期性的, 并且部分地出现
    - 例如序列 ansd `cd` mn `cd` ca `cd` as `cd` mc 中 `cd` 具有周期性, 周期从位置 4 开始, 可以用 PARPER 方法检测
- 分段周期性: 整个序列被表示为一个周期模式

## 傅里叶变换

傅里叶变换是一种将 **时域**、 **空域** 数据转化为 **频域** 数据的方法, 
任何波形(时域)都可以看做是不同振幅、不同相位(频域)正弦波的叠加. 
比如下面最前方的图形就是它后面所有正弦波的总和.

![img](images/FT.png)

对于一条具备周期性的时间序列, 它本身就很接近正弦波, 所以它的组成里一定包含一个显著的正弦波, 
周期就是该正弦波的周期, 而这个正弦波可以通过傅里叶变换找到, 它将时序数据展开成
三角函数的线性组合, 得到每个展开项的系数, 就是傅里叶系数. 
傅里叶系数越大, 表明它所对应的正弦波的周期就越有可能是这份数据的周期. 

- [An Interactive Guide To The Fourier Transform](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/)

## 自相关系数

自相关系数(Autocorrelation Function) 度量的是同一件事不同时间的相关程度.

比如有一个序列 `$X = [1, 2, 3, 5, 7, 9, 13, 14, 17, 19]$`, 求不同相位差的自相关系数

- 相位差为 1 时, 比较的序列是 `$[1, 2, 3, 5, 7, 9, 13, 14, 17]$` 和 `$[2, 3, 5, 7, 9, 13, 14, 17, 19]$`
- 相位差为 2 时, 比较的序列是 `$[1, 2, 3, 5, 7, 9, 13, 14]$` 和 `$[3, 5, 7, 9, 13, 14, 17, 19]$`

不同相位差(lag)序列间的自相关系数可以用 Pearson 相关系数计算:

`$$\begin{align} autocorr(X, t) &= corr[X, lag(X, t)] \\
                              &= \frac{cov[X, lag(X, t)]}{std[X]std[lag(X, t)]} \\
                              &= \frac{cov[X, lag(X, t)]}{var(X)} \\
                              &= \frac{\sum^{N}_{i=1}[X_{i} - mean(X)][X_{i-t} - mean(X)]}{\sum{N}_{i=1}[X_{i} - mean(X)]^{2}}
\end{align}$$`

其中 `$lag(X_{i}, t)=X_{i-1}$` 表示相位 `$t$` 的数据延迟 lag operator

当序列存在周期性时, 遍历足够多的相位差, 一定可以找到至少一个足够大的相关系数, 而它对应的相位差就是周期.

所以对于检测时序周期来说, 只需找到两个自相关系数达到一定阈值的子序列, 反映在时序图上, 就是两段很相似的数据,
它们起始时间的差值就是我们需要的周期. 比如下面的第二张图和第三张图, 它们的序列自相关系数为 1, 起始时间间隔是 12.57, 
正好是第一张图的周期.

![img](images/acf.jpeg)

## 周期性检测流程

### 检测流程

为了保证结果的可靠性, 可以将傅里叶变换和自相关系数结合起来判断周期性. 
主要思路是:

1. 先通过傅里叶变换找到可能的周期
2. 再用自相关系数做排除, 从而得到最可能的周期

![img](images/cycle_detection.png)

### 实例分析

![img](images/cycle_detection_flow.png)

## 周期性检测实践

- 见 `src/timeseries/timeseries_cyclical_detection.py`


# 时间序列季节性检测

## 傅里叶变换

- https://anomaly.io/detect-seasonality-using-fourier-transform-r/


# 时间序列平稳性检验

> 时间序列分析中的许多方法，如 ARMA、ARIMA、Granger 因果检验等时序预测和分析方法，
> 都需要时间序列具备平稳性。那么什么是时间序列的平稳性呢？
> 什么序列是平稳时间序列，什么序列又是非平稳时间序列？

## 时间序列平稳性

### 时间序列平稳性定义

时间序列的平稳性是指在一组时间数据看起来平坦，
各阶统计特性，如：均值、方差、协方差等不随时间时间的变化而变化。
其数学定义又分为严平稳和宽平稳

#### 严平稳

给定随机过程 `$X(t), t \in T$`，如果对任意 `$n \geq 1$`，
`$t_{1}, t_{2}, \ldots, t_{n} \in T$` 和 实数 `$\tau$`，
当 `$t_{1+\tau}, t_{2+\tau}, \ldots, t_{n+\tau}$` 时，
随机变量 `$(X(t_{1}), X(t_{2}), \ldots, X(t_{n}))$` 与 
`$(X(t_{1+\tau}), X(t_{2+\tau}), \ldots, X(t_{n+\tau}))$` 有相同的联合分布函数。
即 

`$$F_{t_{1}, t_{2}, \ldots, t_{n}}(x_{1}, x_{2}, \ldots, x_{m})=F_{t_{1+\tau}, t_{2+\tau}, \ldots, t_{n+\tau}}(x_{1}, x_{2}, \ldots, x_{m})$$`

则称随机过程 `$X_{t}, t \in T$` 是严平稳过程

简单点来说严平稳是一种条件比较苛刻的平稳性定义，
它认为只有当序列所有的统计性质都不会随着时间的推移而发生变化时，该序列才能被认为平稳

#### 宽平稳

假定某个时间序列是由某一随机过程生成的，如果满足下列条件：

1. 均值 `$E(X_{t}) = \mu$` 是与时间 `$t$` 无关的常数
2. 方差 `$Var(X_{t}) = \sigma^{2}$` 是与时间无关的常数
3. 协方差 `$Cov(X_{t}, X_{t+k}) = \gamma_{k}$` 是只与时间间隔 `$k$` 有关，与时间 `$t$` 无关的常数

则该时间序列是宽平稳的，该随机过程是平稳随机过程

平稳性的定义在不同文章中描述略有不同，但它们的意思都是一样的。
比如一些定义中会强调二阶矩存在，而我们当前的这个定义中没有强调，
原因在于均值、方差为常数既已表示一阶矩、二阶矩存在

宽平稳序列具有均值、方差和自相关结构不随时间变化的特性。
简单理解就是一个看起来平坦的序列，没有趋势，随时间变化的方差不变，
随时间变化的自相关结构不变，也没有定期波动（季节性）

#### 严平稳与宽平稳的关系

严平稳比宽平稳的要求更严格，但两者并没有包含关系。通常情况下，
阶矩存在的严平稳能推出宽平稳成立，而宽平稳序列不能反推严平稳成立。

即便严平稳也不一定宽平稳。不存在低阶矩的严平稳序列不满足宽平稳条件，
例如服从柯西分布的严平稳序列就不是宽平稳序列（柯西分布的一阶矩、二阶矩都不存在）

![img](images/kx_dist.png)

当序列服从多元正态分布时，宽平稳可以推出严平稳。
因为正态过程的概率密度是由均值函数和自相关函数完全确定的，
宽平稳则均值函数和自相关函数不随时间的推移而变化，
那么正态过程的概率密度函数也就不会随时间的推移而变化，
所以说一个宽平稳的正态过程必定是严平稳的

* 宽平稳，因其定义，又叫二阶平稳，或者协方差平稳 
* 平稳序列，一般是指宽平稳序列，也称弱平稳序列
* 严平稳序列，也可以叫做强平稳序列

### 平稳时间序列

#### 白噪声

一种最简单的平稳时间序列就是白噪声，白噪声时间序列是具有零均值、同方差的独立同分布序列，
记作 `$\{\varepsilon_{t}\}$`。当 `$\varepsilon_{t}$` 服从均值为 0 的正态分布时，
称 `$\{\varepsilon_{t}\}$` 为高斯白噪声或正态白噪声

对于任意 `$t \in T$`，`$X_{t}$` 均值相同、方差相同，独立则协方差为 0，所以白噪声序列是平稳的

```python
import numpy as np
import matplotlib.pyplot as plt

# 白噪声序列
white_noise = np.random.standard_normal(size = 1000)

# plot
plt.figure(figsize = (12, 6))
plt.plot(white_noise)
plt.show()
```

![img](images/white_noise.png)

当一个序列为白噪声时，表示序列前后没有任何相关关系。过去的行为对将来的发展没有丝毫影响，
从统计分析的角度而言，已没有任何分析建模的价值。未来的趋势亦无法预测，
因为白噪声的取值是完全随机的。此时未来预测为均值就是残差最小的选择。
只有当序列平稳且非白噪声时，应用 ARMA 等分析方法才有意义

通常我们在对时间序列建模之后，还会对残差序列进行白噪声检验，
如果残差序列是白噪声，那么就说明原序列中所有有价值的信息已经被模型所提取，
如果非白噪声就要检查模型的合理性了

#### 非白噪声





## 时间序列平稳性检验

* Augmented DIckey Fuller Test(ADF test)
    - `$p>0$`, 过程不是平稳的
    - `$p=0$`, 过程是平稳的
* Kwiatkowski-Phillips-Schmidt-Shin Test(KPSS test)

## 时间序列平稳性准换

理想情况下,需要一个用于建模的固定时间序列. 当然, 不是所有的时间序列都是平稳的, 
但是可以通过做不同的变换使它们保持平稳

对于非平稳的时间序列, 可以通过 **差分**、**log 变换**、**平方根变换** 转化为平稳序列


# 时间序列趋势性检测

趋势其实就是非平稳, 包括均值、方差等的趋势

* 对均值或方差的趋势检验可以采用分组计算, 再结合游程检验的思路进行
* 如果有趋势, 则需要先提取趋势项再去掉趋势项
* 对趋势项可以采取滤波器消除
* 对于多项式趋势可以采用最小二乘法提取
* 对缓慢变化趋势可采用数据时间窗和最小二乘平滑进行处理


## 移动平均



# 参考

- [[1]时间序列预测](https://mp.weixin.qq.com/s?__biz=Mzg3NDUwNTM3MA==&mid=2247484974&idx=1&sn=d841c644fd9289ad5ec8c52a443463a5&chksm=cecef3dbf9b97acd8a9ededc069851afc00db422cb9be4d155cb2c2a9614b2ee2050dc7ab4d7&scene=21#wechat_redirect)