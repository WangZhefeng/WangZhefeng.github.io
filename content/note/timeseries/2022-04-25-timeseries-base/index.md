---
title: 时间序列分析-基础
author: 王哲峰
date: '2022-04-25'
slug: timeseries-base
categories:
  - timeseries
tags:
  - ml
---

# 时间序列介绍

时间序列(time series, TS) 是一组按照时间发生先后顺序进行排列的数据点序列. 
通常一组时间序列的时间间隔为一恒定值(如 1s, 5s, 1min, 1h, 1d 等). 
因此时间序列亦可作为离散时间数据进行分析处理.

时间序列的主要研究领域有: 

- 时间序列异常检测(timeseries anomaly detection)      
   - 从时间序列中识别异常的事件或行为, 异常检测算法目前广泛应用于众多领域中, 例如量化交易, 网络入侵检测、智能运维等   
- 时间序列预测(timeseries forcasting)

## 时间序列类型

在实际场景中, 不同的业务通常会对应不同类型的时间序列模式, 
一般可以划分为几种类型: 趋势性、周期性、随机性、综合性.

下图中展示了几种常见的时间序列的类型: 

- smooth(stationary) 
- multi model
- irregular sampling
- sparse
- discrete
- step

![img](images/timeseries_class.png)

# 1.时间序列处理

## 时间序列的性质

- 1.平稳性
   - 平稳性是指如果时间序列在一段时间内的统计性质不随时间变化, 则称该时间序列是平稳的, 
      即: 该时间序列有不变的均值和方差, 协方差不随时间变化. 通常, 股票价格不是一个平稳的过程, 
      因为可能看到一个增长的趋势, 或者其波动性会随着时间的推移而增加(方差在变). 理想情况下,
      需要一个用于建模的固定时间序列. 当然, 不是所有的时间序列都是平稳的, 但是可以通过做不同的变换使它们保持平稳
   - 如何检测过程是否平稳?
      - Augmented DIckey Fuller Test(ADF test)
         - p>0, 过程不是平稳的
         - p=0, 过程是平稳的
      - Kwiatkowski-Phillips-Schmidt-Shin Test(KPSS test)
   - 如何使得序列稳定?
      - 对于非平稳的时间序列, 可以通过 $差分$、 $log 变换$ 、 $平方根变换$ 转化为平稳序列
- 2.趋势性
   - 当一个时间序列数据长期增长或长期下降时, 表示该序列有趋势. 在某些场合, 趋势代表着“转换方向”
- 3.季节性
   - 当时间序列中的数据受到季节性因素(例如一年的时间或者一周的时间)的影响时, 表示该序列具有季节性
      季节性总是一个已知并且固定的频率
- 4.周期性
   - 当时间序列数据存在不固定频率的上升和下降时, 表示该序列有 周期性. 周期波动通常至少持续两年 
   - 周期性和季节性的区别: 当数据的波动是无规律时, 表示序列存在周期性; 
      如果波动的频率不变并且与固定长度的时间段有关, 表示序列存在季节性. 
      一般而言, 周期的长度较长, 并且周期的波动幅度也更大. 
- 5.自相关
   - 自相关指的是时间序列中某一时刻的值和另一时刻的值具有一定的相关性, 通常用于时间序列的周期性检测
- 6.白噪声   
   - 白噪声是一个对所有时间其自相关系数为零的随机过程. 即任何两个时间的随机变量都不相关
- 7.虚假相关性
   - 很多变量间的序列相关性非常强, 但是实际上很可能是虚假相关性
- 8.随机噪声

## 时间序列数据处理方法

- 1.平稳性检验
   - 平稳是说系统参数不随时间变化, 可采用参数检验法(分组, 组间差异不应太大)和
      非参数检验法(游程检验, 游程应适中, 即样本数据出现的顺序没有趋势)进行检验. 包括: 
      - 均值、方差是否为常数
      - 自相关函数是否只于时间间隔有关
- 2.正态性检验
   - 模型噪声需要是高斯白噪声. 可采用 P-P 图和 Q-Q 图直观上进行判断, 也可以采用卡方拟合优度检验正态性(落入各组的频数与理想期望接近)
- 3.独立性检验
   - 独立的白噪声序列的自相关系数是冲激函数, 则序列的自相关系数需接近冲激函数才能认为是独立的
- 4.周期性检验
   - 分析序列中的周期性或准周期序列(如季节、星期等), 可通过直观比较得到周期性的定性结果:
      - 周期序列的功率谱会产生尖峰
      - 自相关系数是连续振荡波形
      - 数据的概率密度直方图是下凸, 非周期是上凸
- 5.趋势项检验
   - 趋势其实就是非平稳, 包括均值、方差等的趋势. 对均值或方差的趋势检验可以采用分组计算, 再结合游程检验的思路进行. 
      如果有趋势, 则需要先提取趋势项再去掉趋势项. 对趋势项可以采取滤波器消除, 而对于多项式趋势可以采用最小二乘法提取. 
      对缓慢变化趋势可采用数据时间窗和最小二乘平滑进行处理
- 6.异常值检测、处理
   - 异常的定义: 在时间序列中, 异常是指在一个或多个信号的模式发生意料之外的变化. 主要可以分为一下三种异常:
      - 点异常(point anomalies): 某些点与全局大多数都不一样
      - 上下文异常(contextual anomalies) 某个时间点的表现与前后时间段内存在较大差异
      - 集合异常(collective anomalies) 个体不存在异常, 但是个体同时出现表现出异常状态
   - 时间序列预测方法可以用于异常检测
      - 基于统计
         - 基于统计置信检验
            - 3-sigma: 值在 $(\mu - 3\sigma, \mu + 3\sigma)$ 区间的概率为 99.74%, 
               当数据分布超过这个区间时即认为是异常数据, 为提升准确率可采用同环比策略
            - t 检验
            - f 检验
            - 卡方检验
         - ARIMA 系列模型
         - 基于极值优化
      - 基于度量
         - 基于距离
            - kNN
         - 基于密度
         - 基于聚类 
            - k-means
            - DBSCAN
            - GMM
         - 基于树
            - iForest
            - RRCF
         - 基于谱
         - 基于单分类
      - 基于深度学习
         - CNN 系列
         - AutoEncoder 系列
         - Attention 系列
      - 多变量时间序列
         - 基于线性回归
            - VAR
            - VARMA
            - VARMAX
         - AutoEncoder 系列
         - 图神经网络系列
- 7.缺失值检测、处理
   - 最常用的处理缺失值的方法包括填补(imputation) 和删除(deletion)两种
   - 常见的数据填补(imputation)方法:
      - forward fill 和 backward fill: 根据缺失值前/后的最近时间点数据填补当前缺失值
      - moving average
      - interpolation: 插值方法要求数据和邻近点之间满足某种拟合关系, 因此插值法是一种先验方法且需要代入一些业务经验
- 8.时间序列平滑
   - 数据平滑通常是为了消除一些极端值或测试误差. 即使有些极端值本身是真实的, 但是并没有反映出潜在的数据模式, 仍需处理
   - 数据平滑方法
      - 移动平均(weighted averaging, moving average), 既可以给定时间窗口内样本点相同权重, 或邻近点指定更高权重
      - 指数平滑(exponential smoothing), 所有的指数平滑法都要更新上一时间步长的计算结果, 并使用当前时间步长的数据中包含的新信息.
         通过"混合"新信息和旧信息来实现, 而相关的新旧信息的权重由一个可调整的参数来控制
         
         - 一次指数平滑(exponential smoothing), 从最邻近到最早的数据点的权重呈现指数型下降的规律, 针对没有趋势和季节性的序列
         - 二次指数平滑(Holt exponential smoothing), 通过引入一个额外的系数来解决指数平滑无法应用于具有趋势性数据的问题, 
            针对有趋势但没有季节性的序列
         - 三次指数平滑(Holt-Winters exponential smoothing), 通过再次引入一个新系数的方式同时解决了二次平滑无法解决具有季节性变化数据的不足
      - 差分运算
      - 时间序列分解
      - 日历调增
      - 数学变换
- 9.数据采样
   - 通常来自不同数据源的时间轴常常无法一一对应, 此时就要用到改变时间频率的方法进行数据处理. 
      由于无法改变实际测量数据的频率, 我们能做的是改变数据收集的频率
      - 上采样(up sampling): 在某种程度上是凭空获得更高频率数据的方式, 不增加额外的信息
      - 下采样(down sampling): 减少数据收集的频率, 也就是从原始数据中抽取子集的方式
- 10.对时间序列数据建立机器学习模型的数据处理方法
   - 特征构建
      - 基本日期时间特征
      - Lagging 特征
      - Window 特征
   - 交叉验证数据分割
      - Train-Test split
      - Multiple Train-Test split
      - Walk-Forward Validation
- 11.傅里叶变换
- 12.小波分析
- 13.滤波
- 14.时间序列可视化

# 时间序列数据处理工具

- pandas
   - Date & Time
   - Index
   - Missing value
      - $pandas.DataFrame.ffill()$
      - $pandas.DataFrame.bfill()$
      - $fillna()$
      - $pandas.DataFrame.iterpolate()$
   - Window Functions:
      - rolling window
      - expanding window
   - Resample/频率变换
      - 上采样
         - $ts.resample().ffill()$
         - $ts.resample().bfill()$
         - $ts.resample().pad()$
         - $ts.resample().asfreq()$
         - $ts.resample().interpolate()$
      - 降采样
         - $ts.resample()$
         - $ts.resample().apply()$
         - $ts.resample().aggregate()$
         - $ts.resample().transform()$
         - $ts.resample().pipe()$
   - Difference
      - $pandas.DataFrame().diff()$
      - $pandas.Series().diff()$
   - Move Average
      - $pandas.DataFrame().rolling()$
      - $pandas.Series().rolling()$
   - Random Walk

# 时间序列预测

## 基于业务场景理解的因子预测模型

基于因子的时序预测是一种传统的预测手法, 在一些特定场景有着比较好的表现, 比如某条业务线刚起步, 
历史数据的积累有限的时候. 同时该方法基于其业务解释性强、准确率也比较高的特点, 可以作为时序预测项目的 baseline, 
并且在黑盒模型做输出时, 可以帮助进行后置校准, 避免输出较大的偏差. 

### 需要展示的客流量预测

需要进行展示的客流量预测这样的场景, 是一个模型解释性要求比较高, 同时周期性较强的场景. 
那么对于这样的业务场景, 可以考虑分解出最重要的周期因子, 来进行可解释地稳定地预测. 
具体实施的时候: 考虑到时间序列数值除了受本身业务的影响, 存在固定的周期性波动, 
同时还会受到已知或者未知事件的影响. 因此在预测时, 会单独将一些已知的重要事件单独进行预估, 
在基础预测的再叠加事件的影响. 

这样的场景, 因子预测的公式可以是: 某日话务量 = 日话务基准量 * 周规律因子 * 事件影响因子

- 周规律因子的计算逻辑: 基于对一段时间的周规律因子总结, 可以得到周规律因子(可以以日话务量与周话务总量的比例关系来做因子, 也可以以相邻几天日话务量之间的比例关系来做因子)
- 日话务基准量: 基于周规律因子, 可以用来计算每一天的日话务基准量
- 没有叠加事件影响因子的日话务预测量: 基于日话务基准量预测的未来日话务基准量 * 周规律因子
- 事件影响因子的计算逻辑: 可以通过整理出历史上该事件带来的额外话务量(实际量减去预测量)来计算

### 一条新开拓的国际业务线

一条刚开始快速成长的国际业务线, 特点是历史数据积累有限, 同时数据量变化大. 
可能仅仅只能拿到 2 个月的数据, 并且短时间内时序数据的性质(均值、方差)就会有极大的改变. 
因此用历史数据来预测未来的历史数据的参考性较低, 所以需要深入业务去理解, 
找寻该业务特有的相关因子来进行预测, 思路可以是: 

- 首先基于业务相关度进行挖掘(未来入住需求量与售前话务量强相关, 新市场新签用户数与未来下单量强相关)
- 然后基于树模型的特征重要性进行核心影响因子的识别, 来选择出最为重要的因子特征
- 最后基于统计学模型对核心影响因子的未来数值进行预测, 并在此基础上预测未来的业务线状态

## 传统时间序列建模

传统时间序列预测模型, 通常指用于时间序列分析/预测的统计学模型, 比如常用的有均值回归、ARIMA、指数平滑预测法等. 

其中均值回归, 指对历史一段时间的值取平均, 作为未来每个时刻的预测. 
其他时间序列预测模型比如 ARIMA(auto-regressive integrated moving average)、
一些指数平滑模型(SEM, Holt-Winters等), 主要通过对历史数据的建模分析, 抽离出其中的趋势, 
最后通过对趋势的预测得到未来一段时间需求的变化. 

基于统计学的传统时间序列预测方法, 优点是复杂度低、计算速度快. 但是有其局限性, 通过对业界方法的调研与自己的实验, 
我们发现由于真实应用场景的复杂多样性(现实世界的时间序列往往受到各种不同因素的限制与影响, 而难以预测), 
比如受到营销计划、自然灾害等的影响, 传统的单一统计学模型的准确率相对来说会比机器学习差一部分, 
而机器学习模型或者更复杂的 ensemble 集成模型会有更好的效果. 但传统时间序列预测模型也有其重要的意义, 比如说: 

- 可以作为预测的 baseline model, 为项目提供一个准确率的基准线, 来帮助评估其他模型的提升. 前置清洗作用, 
时序模型由于其较好的可解释性, 可以帮助剔除一些异常值, 比如因服务器故障或者业务线逻辑调整产生的异常值. 
作为集成模型中的一块, 参与时序集成模型的训练. 
- 可以提供一个预测结果的合理的范围, 因为话务量通常不会短时间内激增. 使用这个合理的范围, 
在黑盒模型最后输出结果时, 帮忙进行后置校准, 从而使预测系统更加稳定. 

时间序列预测的问题, 并不是普通的回归问题, 而是 **自回归**

- 一般的回归问题比如最简单的线性回归模型: $Y=a \cdot X_1+b \cdot X_2$, 讨论的是因变量 $Y$
   关于两个自变量 $X_1$ 和 $X_2$ 的关系, 目的是找出最优的
   $a$ 和 $b$ 来使预测值 $y=a \cdot X_1+b \cdot X_2$ 逼近真实值 $Y$.
- 自回归模型中, 自变量 $X_1$ 和 $X_2$ 都为 $Y$ 本身,
   也就是说 $Y(t)=a \cdot Y(t-1)+ b \cdot Y(t-2)$,其中
   $Y(t-1)$ 为 $Y$ 在 $t-1$ 时刻的值, 而
   $Y(t-2)$ 为 $Y$ 在 $t-2$ 时刻的值, 换句话说, 现在的
   $Y$ 值由过去的 $Y$ 值决定, 因此自变量和因变量都为自身,
   因此这种回归叫自回归.
- 自回归模型都有着严格理论基础,讲究时间的平稳性,
   需要对时间序列进行分析才能判断是否能使用此类模型.
   这些模型对质量良好的时间序列有比较高的精度. 传统的自回归模型有: 
   - 移动平均
   - 指数平滑
   - 自回归模型(AR)
   - 移动平均模型(MA)
   - 自回归移动平均模型(ARMA)
   - 差分自回归移动平均模型(ARIMA)

### 平稳时间序列分析

一个时间序列经过预处理被识别为 **平稳非白噪声时间序列**, 就说明该序列是一个蕴含相关信息的平稳序列. 
在统计上, 通常是建立一个线性模型来拟合该序列的发展, 借此提取该序列中的有用信息. 
ARMA(auto regression moving average)模型就是目前最常用的平稳序列拟合模型.

假设一个时间序列经过预处理被识别为 **平稳非白噪声时间序列**, 就可以利用ARMA 模型对该序列建模. 建模的基本步骤为:

1. 求出该观察序列的 **样本自相关系数(ACF)** 和 **样本偏自相关系数(PACF)** 的值;
2. 根据样本自相关系数和偏自相关系数的性质,选择阶数适当的 ARMA($p$, $q$)模型进行拟合;
3. 估计模型中的位置参数的值;
4. 检验模型的有效性;
   - 如果拟合模型通不过检验,转向步骤2,重新选择模型再拟合
5. 模型优化.
   - 如果拟合模型通过检验,仍然转向步骤2,充分考虑各种可能,建立多个拟合模型,从所有通过检验的拟合模型中选择最优模型
6. 利用拟合模型,预测序列的将来走势.

#### 差分

**差分运算:**

$p$ 阶差分: 相距一期的两个序列值至之间的减法运算称为 $1$
阶差分运算; 对 $1$ 阶差分后序列在进行一次 $1$ 阶差分运算称为
$2$ 阶差分; 以此类推, 对 $p-1$ 阶差分后序列在进行一次
$1$ 阶差分运算称为 $p$ 阶差分.

$$\Delta x_{t} = x_{t-1} - x_{t-1}$$

$$\Delta^{2} x_{t} = \Delta x_{t} - \Delta x_{t-1}$$

$$\Delta^{p} x_{t} = \Delta^{p-1} x_{t} - \Delta^{p-1} x_{t-1}$$

$k$ 步差分: 相距 $k$ 期的两个序列值之间的减法运算称为
$k$ 步差分运算.

$$\Delta_{k}x_{t} = x_{t} - x_{t-k}$$

**滞后算子**

滞后算子类似于一个时间指针, 当前序列值乘以一个滞后算子, 就相当于把当前序列值的时间向过去拨了一个时刻.

假设 $B$ 为滞后算子:

$x_{t-1} = Bx_{t}$

$x_{t-2} = B^{2}x_{t}$

$\vdots$

$x_{t-p} = B^{p}x_{t}$

也可以用滞后算子表示差分运算:

- $p$ 阶差分

   - $\Delta^{p}x_{t} = (1-B)^{p}x_{t} = \sum_{i=0}^{p}(-1)C_{p}^{i}x_{t-i}$

- $k$ 步差分

   - $\Delta_{k}x_{t} = x_{t} - x_{t-k} = (1-B^{k})x_{t}$

**线性差分方程**

#### ARMA模型

ARMA 模型的全称是 **自回归移动平均模型**,它是目前最常用的拟合平稳序列的模型.它又可以细分为
AR 模型, MA 模型, ARMA 模型三类.

**AR($p$) 模型**

AR($p$) 模型结构:

$$
\left\{
\begin{array}{**lr**}
x_{t}=\phi_{0} + \phi_{1}x_{t-1} + \phi_{2}x_{t-2} + \cdots + \phi_{p}x_{t-p} + \epsilon_{t} & \\
\phi_{p} \neq 0 & \\
E(\epsilon_{t}) = 0, Var(\epsilon_{t}) = \sigma_{\epsilon}^{2}, E(\epsilon_{t}\epsilon_{s}) = 0, s \neq t & \\
E(x_{s}\epsilon_{t}) = 0, \forall s < t & 
\end{array}
\right.
$$

其中: 

- $\epsilon_{t}$ 是白噪声序列
- $\phi_{0}$ 是常数, 表示时间序列没有进行 0 均值化

AR($p$) 模型的统计性质:

- 均值
- 方差
- 自协方差函数
- 自相关系数
- 偏自相关系数

**MA($q$) 模型**

MA($q$) 模型结构:

$$
\left\{
\begin{array}{**lr**}
x_{t}=\mu + \epsilon_{t} + \theta_{1}\epsilon_{t-1} + \theta_{2}\epsilon_{t-2} + \cdots + \theta_{q}\epsilon_{t-q}& \\
\theta_{q} \neq 0 & \\
E(\epsilon_{t}) = 0, Var(\epsilon_{t}) = \sigma_{\epsilon}^{2}, E(\epsilon_{t}\epsilon_{s}) = 0, s \neq t &
\end{array}
\right.
$$

其中: 

- $\epsilon_{t}$ 是白噪声序列
- $\mu$ 是常数

MA($q$) 模型的统计性质:

- 常数均值
- 常数方差
- 自协方差函数只与滞后阶数相关, 且 $q$ 阶截尾
- 自相关系数 $q$ 阶截尾

**ARMA($p$, $q$) 模型**

ARMA($p$, $q$) 模型结构:

$$
\left\{
\begin{array}{**lr**}
x_{t}=\phi_{0} + \phi_{1}x_{t-1} + \phi_{2}x_{t-2} + \cdots + \phi_{p}x_{t-p} + \epsilon_{t} + \theta_{1}\epsilon_{t-1} + \theta_{2}\epsilon_{t-2} + \cdots + \theta_{q}\epsilon_{t-q} & \\
\phi_{p} \neq 0, \theta_{q} \neq 0& \\
E(\epsilon_{t}) = 0, Var(\epsilon_{t}) = \sigma_{\epsilon}^{2}, E(\epsilon_{t}\epsilon_{s}) = 0, s \neq t & \\
E(x_{s}\epsilon_{t}) = 0, \forall s < t & 
\end{array}
\right.
$$

ARMA 模型的另一种形式: 


      
$$(1-\sum_{i=1}^{p}\phi_{i}B^{i})x_{t} = (1 - \sum_{i=1}^{q}\theta_{i}B^{i})\epsilon_{t}$$

$$\Phi(B)x_{t} = \Theta(B)\epsilon_{t}$$

- 当 $q = 0$ 时, ARMA($p$, $q$) 模型就退化成了 AR($p$) 模型.
- 当 $p = 0$ 时, ARMA($p$, $q$) 模型就退化成了 MA($q$) 模型.
- 所以 AR($p$) 和 MA($q$) 实际上是 ARMA($p$, $p$) 模型的特例, 
  它们统称为 ARMA 模型. 而 ARMA($p$, $p$) 模型的统计性质也正是 AR($p$) 模型和
  MA($p$) 模型统计性质的有机结合.

ARMA($p$, $q$) 模型的统计性质:

- 均值
- 自协方差函数
- 自相关系数

### 非平稳时间序列分析

在自然界中绝大部分序列都是非平稳的,因而对非平稳序列的分析更普遍、更重要.
对非平稳时间序列分析方法可以分为 **随机时间序列分析** 和 **确定性时间序列分析**.

 - 时间序列的分解
 - 差分运算
 - ARIMA 模型

差分运算具有强大的确定性信息提取能力, 许多非平稳序列差分后会显示出平稳序列的性质, 称这个非平稳序列为差分平稳序列, 对差分平稳序列可以使用
ARIMA(autoregression integrated moving average, 求和自回归移动平均)
模型进行拟合.

ARIMA 模型的实质就是差分运算和 ARMA
模型的组合, 说明任何非平稳序列如果能通过适当阶数的差分实现差分后平稳, 就可以对差分后序列进行
ARMA 模型拟合, 而 ARMA 模型的分析方法非常成熟.

**ARIMA($p$, $d$, $q$) 模型**

ARIMA($p$, $d$, $q$) 模型结构
      
$$
\left\{
\begin{array}{**lr**}
\Phi(B)\Delta^{d}x_{t} = \Theta(B)\epsilon_{t}& \\
E(\epsilon_{t}) =0, Var(\epsilon_{t}) = \sigma_{\epsilon}^{2}, E(\epsilon_{s}\epsilon_{t}) = 0, s \neq t& \\
E(x_{s}\epsilon_{t}) = 0, \forall s < t&
\end{array}
\right.
$$

其中: 

- ${\epsilon_{t}}$ 为零均值白噪声序列
- $\Delta^{d} = (1-B)^{d}$
- $\Phi(B) = 1-\sum_{i=1}^{p}\phi_{i}B^{i}$ 为平稳可逆 ARMA($p$, $q$) 模型的自回归系数多项式
- $\Theta(B) = 1 + \sum_{i=1}^{q}\theta_{i}B^{i}$ 为平稳可逆 ARMA($p$, $q$) 模型的移动平滑系数多项式

ARIMA 之所以叫 **求和自回归移动平均** 是因为: $d$ 阶差分后的序列可以表示为下面的表示形式, 
即差分后序列等于原序列的若干序列值的加权和, 而对它又可以拟合 ARMA 模型: 

$$\Delta^{d}x_{t} = \sum_{i=0}^{d}(-1)C_{d}^{i}x_{t-i}, 其中: C_{d}^{i} = \frac{d!}{i!(d-i)!}$$

ARIMA 模型的另一种形式: 
   
$$\Delta^{d}x_{t} = \frac{\Theta(B)}{\Phi(B)}\epsilon_{t}$$

其中: 

   - 当 $d=0$ 时 ARIMA($p$, $0$, $q$) 模型就是
      ARMA($p$, $q$) 模型
   - 当 $p=0$ 时, ARIMA($0$, $d$, $q$)
      模型可以简记为 IMA($d$, $q$) 模型
   - 当 $q=0$ 时, ARIMA($p$, $d$, $0$)
      模型可以简记为 ARI($p$, $d$) 模型
   - 当 $d=1, p=q=0$ 时, ARIMA($0$, $1$, $0$)
      模型为 随机游走 (random walk) 模型:

         
$$
\left\{
\begin{array}{**lr**}
x_{t} = x_{t-1} + \epsilon_{t}& \\
E(\epsilon_{t}) =0, Var(\epsilon_{t}) = \sigma_{\epsilon}^{2}, E(\epsilon_{s}\epsilon_{t}) = 0, s \neq t& \\
E(x_{s}\epsilon_{t}) = 0, \forall s < t&
\end{array}
\right.
$$

**ARIMA($p$, $d$, $q$) 模型的统计性质:**

   1. 平稳性
   2. 方差齐性

**ARIMA 模型建模:**

   1. 获得时间序列观察值
   2. 平稳性检验
      - 不平稳: 差分运算 => 平稳性检验
      - 平稳: 下一步
   3. 白噪声检验
      - 不通过: 拟合 ARMA 模型 => 白噪声检验
      - 通过: 分析结束

### 多元时间序列分析

- 移动平均
   - 移动平均模型是最简单的时间序列建模方法, 即: 下一个值是所有一个时间窗口中值的平均值
   - 时间窗口越长, 预测值的趋势就越平滑
- 指数平滑
   - 指数平滑使用了与移动平均相似的逻辑, 但是, 指数平滑对每个观测值分配了不同的递减权重, 即: 离现在的时间距离越远, 时间序列观测值的重要性就越低
   - 指数平滑的数学表示:       

$$y=\alpha x_{t} + (1 - \alpha)y_{t-1}, t>0$$

其中:

- $\alpha \in [0, 1]$ 是一个平滑因子, 决定了之前观测值的权重下降的速度. 
   平滑因子越小, 时间序列就越平滑, 因为当平滑因子接近0时, 指数平滑接近移动平均模型


- 双指数平滑
   - 当时间序列中存在趋势时, 使用双指数平滑, 它只是指数平滑的两次递归使用
   - 双指数平滑的数学表示:       

$$y=\alpha x_{t} + (1 - \alpha)(y_{t-1} + b_{t-1})$$
$$b_{t}=\beta (y_{t} - y_{t-1}) + (1 - \beta)b_{t-1}$$

其中:
  - $\alpha \in [0, 1]$ 是一个平滑因子
  - $\beta \in [0, 1]$ 是趋势平滑因子

- 三指数平滑
   - 三指数平滑通过添加季节平滑因子扩展双指数平滑
   - 三指数平滑的数学表示:       

$$y=\alpha \frac{x_{t}}{c_{t-L}} + (1 - \alpha)(y_{t-1} + b_{t-1})$$

$$b_{t}=\beta (y_{t} - y_{t-1}) + (1 - \beta)b_{t-1}$$

$$c_{t}=\gamma \frac{x_{t}}{y_{t}} + (1-\gamma)c_{t-L}$$

其中:

   - $\alpha \in [0, 1]$ 是一个平滑因子
   - $\beta \in [0, 1]$ 是趋势平滑因子
   - $\gamma$ 是季节长度

## 应用机器学习进行时间序列

在运用机器学习模型时, 我们可以把时间序列模型当成一个回归问题来解决, 常见的方法有树模型与神经网络模型两大类. 

### 树模型

一般采用的是 xgboost 或者 lightgbm 的方法, 现在业界也被广泛应用, 这里就不多做介绍了. 
树模型的一个好处就是, 相对于以上的方法, 能更方便地添加一些 category 类的特征比如: 
是否季节末、是否公共价格、是否营业时间等. 

在用树模型做时间序列预测时, 特征工程的核心要点在于如何从历史的数据中抽取特征, 这里介绍一些特征构建的经验: 

   - 离散类时间特征: 年月日时分数, 周几, 一年中的第几天, 第几周, 一天中的哪个时间段等
   - 判断类时间特征: 是否调休, 是否周末, 是否公共假期等
   - 滑窗类时间聚合特征: 过去X天平均值, 过去X天方差, 过去X天最大值, 过去X小时四分位数, 过去X天偏态系数等
   - 其他时序模型的预测值作为特征: ARIMA、SARIMA、指数平滑等
   - 其他相关业务线数据的引入: 比如对于售后业务线, 引入售前业务线/预定业务线等数据, 帮忙进行售后业务线的预测

### 神经网络模型

常见的利用神经网络技术来做时间序列预测的方法有有 CNN、RNN、LSTM、GRU等. 

相对于传统的树模型需要人工构建相关模型特征, 神经网络模型通常需要喂入大量的数据来进行训练, 
因此如果同类时序的数据量够多(有够多彼此间相关性较强的时序), 
那么训练一个通用型的端对端的神经网络预测有时也有不错的效果, 比如使用 LSTM 一方面可以较容易地整合外部变量, 
另一方面 LSTM 有能较好地自动提取时序特征的能力. 

在某条业务产线上, 我们针对多城市的数据进行建模, 训练了一个灵活单一通用的端对端 LSTM 时间预测模型. 
具体在训练时, 输入数据一方面包括了时间序列相关的数据, 另一方面也包括了天气、节假日等外部变量, 
同时使用了 encoder-decoder 来帮助提取时序特征, 在 T+14 的主要大城市时序预测上有较大的提升, 达到日 95%+ 的准确率. 

同时, 在实践中, 我们发现对于一些产线, 采用多任务学习的方法, 可以有效地提高模型的泛化性以及准确率, 
比如预测未来某天某些时段的值时, 将不同时段的值作为不同的任务目标来进行学习, 
或者是加入相关性很强的其他时序数据来作为不同的任务目标. 

# 一些经验与思考

1. 训练测试数据的划分
   - 和其他机器学习场景不同, 时间序列预测的数据是带有前后顺序的序列数据, 因此在做训练测试数据的划分时, 
      要注意不能泄露测试数据给模型, 因此在做训练测试数据划分时, 需要让测试数据全都在训练数据的时间戳之后. 
2. 一线业务人员经验的使用
   - 在做一些时间序列预测场景时, 我们发现一线业务人员经验是极其宝贵的, 比如说一些抚平/剔除业务异常数据的经验, 
      他们会知道在历史数据里哪些时间段的数据是异常的原因是什么, 比如各种事件会对不同的业务线产生什么样的影响、
      一些预测偏差较大的原因可能是什么. 这些宝贵的经验可以转化成时间序列历史数据清洗的规则,
      或者是一些时间序列数据校准的 Knowledge Base. 
3. 利用能反映未来的信息
   - 当我们在做时间序列预测时, 本质我们是在利用历史数据来预测未来, 那么如果我们能够拿到更多关于未来的信息, 
      则可以帮助我们预测的更准. 什么是关于未来的信息呢？比如说: 用户的预订信息, 用户的浏览数据, 
      这些数据能够侧面反映用户对于未来某天的兴趣值, 从而帮助我们窥探未来. 
4. 如何保证输出结果的稳定性
   - 在使用黑盒模型时, 我们会发现有时模型输出会存在一些异常点, 这可能是由于历史数据中存在一些没有被剔除的噪音, 
      因此我们需要构建多种可解释性强的预测尺度范围, 来校准最后的输出结果, 从而提高模型输出的稳定性, 
      生产中这样的校准有时也可以提高一定的准确率. 
5. 重新训练模型的频率
   - 通常, 当有新数据获得时, 重新训练模型来进行预测, 整体来说在每个时间戳能给出更好的预测结果. 
      如果生产上准备采取这种思路的话, 在训练的时候也要用相同的重新训练的方法, 来评估哪种模型效果最好, 
      即采用sliding window / expanding window 的方法去在每个时间戳重新训练预测和记录误差来进行模型评估. 
      当然这样计算量会比较大, 比较适合单一产线并且对准确率较为看中的场景. 
6. 如何评估模型的好坏
   - 对于不同的项目, 评判时序预测模型好坏的标准是不同的, 整体来说, 要针对不同的项目场景, 
      综合模型准确率、可维护性、可解释性、稳定性等多方面去评估一个预测模型或者一个预测框架的合理性和实用性. 
7. 历史数据该相信多少
   - 事物是不断发展变化的, 比如随着智能客服智能化程度的提高, 需要人工客服处理的订单会逐渐变少, 
      因此人工客服相关的时间序列数据的性质会处于不断变化之中, 那么我们对于越久远的历史数据的信任度应该是要逐渐下降的. 
      处理的方法是一方面我们可以通过分析来判断训练应该取多久内的时间序列数据, 
      另一方面我们在训练时可以赋予越近的数据更高的权重. 

5.reference
---------------------------------------

- [R package forecast](https://cran.r-project.org/web/packages/forecast/)
- [从数据中提取季节性和趋势](https://anomaly.io/seasonal-trend-decomposition-in-r/index.html)
- [正态分布异常值检测](https://anomaly.io/anomaly-detection-normal-distribution/index.html)
- [季节性地调整时间序列](https://anomaly.io/seasonally-adjustement-in-r/index.html)
- [检测相关时间序列中的异常](https://anomaly.io/detect-anomalies-in-correlated-time-series/index.html)
- [用移动中位数分解检测异常](https://anomaly.io/anomaly-detection-moving-median-decomposition/index.html)
