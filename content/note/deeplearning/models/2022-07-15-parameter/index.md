---
title: 参数初始化和超参数的调优
author: 王哲峰
date: '2022-07-15'
slug: parameter
categories:
  - deeplearning
tags:
  - model
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
</style>

<details><summary>目录</summary><p>

- [参数初始化](#参数初始化)
  - [Xavier初始值](#xavier初始值)
  - [He初始值](#he初始值)
- [超参数的调优](#超参数的调优)
- [参考](#参考)
</p></details><p></p>


# 参数初始化

- 在神经网络的学习中, 权重 `$W$` 的的初始值特别重要。设定什么样的权重初始值, 经常关系到神经网络的学习能否成功;
- 不能将权重初始值全部设为 0，因为在误差反向传播中, 所有权重都会进行相同的更新
    - 比如: 在 2 层神经网络中, 假设第 1 层和第 2 层的权重为 0, 这样一来, 正向传播时, 
      因为输入层的权重是 0, 所有第 2 层的权重神经元全部会被传递相同的值。
      第 2 层的神经元中全部输入相同的值, 这意味着反向传播时第2层的权重全部都会进行姓童的更新, 
      因此, 权重被更新为相同的值, 并拥有了对称的值, 这使得神经网络拥有许多不同的权重的意义就丧失了
- 为了防止“权重均一化”, 必须随机生成初始值
- 梯度消失(gradient vanishing)
- 当使用 sigmoid 函数作为激活函数时, 激活层的激活值呈偏向0和1的分布, 随着输出不断靠近 0 或 1, 
  它导数的值逐渐接近 0, 因此, 偏向 0 和 1 的数据分布会造成反向传播中梯度的值不断减小, 
  最后消失。层次加深的深度学习中, 梯度消失的问题更加严重; 
- 表现力受限
- 如果有多个神经元都输出几乎相同的值, 那他们就没有存在的意义了。
  比如, 如果 100 个神经元都输出几乎相同的值, 那么也可以由1个神经元来表示基本相同的事情。
  因此, 激活值在分布上有所偏向
- 各层的激活函值的分布都要求有适当地广度
    - 因为通过在各层间传递多样性的数据, 神经网络可以进行高效的学习, 
      反之, 如果传递的是有所偏向的数据, 就会出现梯度消失或者“表现力受限”的问题, 
      导致学习无法顺利进行

## Xavier初始值

在Xavier Glorot等人的论文中, 推荐了权重初始值, 俗称“Xavier初始值”。
在一般的深度学习框架中, Xavier初始值已经被作为标准使用

Xavier的论文中, 为了使各层的激活值呈现出具有相同广度的分布, 
推导了合适的权重尺度

**结论:**

* 如果前一层的节点数为 `$n$`, 则初始值使用标准差为 `$\frac{1}{\sqrt{n}}$` 的分布

## He初始值

Xavier 初始值是以激活函数是线性函数为前提推导出来的, 因为 sigmoid 函数和 tanh 函数左右对称, 
且中央附近可以视作线性函数, 所以适合使用 Xavier 初始值;

当激活函数使用 ReLU 函数时, 一般推荐 ReLU 专用的初始值, 
Kaiming He 等人推荐了一种初始值, 俗称 “He 初始值”

**结论:**

* 如果前一层的节点数为 `$n$`, 则初始值使用标准差为 `$\sqrt{\frac{2}{n}}$` 的高斯分布
* 当激活函数使用 ReLU时, 权重初始值使用 **He初始值**
* 当激活函数为sigmoid或tanh等S型函数时, 初始值使用 **Xavier初始值**

# 超参数的调优

- 神经网络中的超参数是指, 各层的神经元数量, batch大小, 参数更新时的学习率, 权值衰减参数(正则化参数)等
- 不能使用测试数据评估超参数的性能
- 调整超参数时, 必须使用超参数专用的确认数据, 用于调整超参数的数据一般称为验证数据(validation data)
- 模型训练数据的使用:
    - 训练数据用于参数(权重和偏置)的学习
    - 验证数据用于超参数的性能评估
    - 测试数据确认泛化能力, 要在最后使用(比较理想的是只用一次)

# 参考

* https://mp.weixin.qq.com/s/Wx1WMvQQQUV46ckGbE3Eag

