---
title: Transformer
author: 王哲峰
date: '2022-04-05'
slug: transformer
categories:
  - nlp
tags:
  - tool
---

# 全局看 Transformer


# 加入张量看 Transformer

# 编码

# 从高处看 Self-attention

# 从细节看 Self-attention

# Self-attention 的矩阵计算

# 多头野兽


# 使用位置编码表征序列顺序

# 残差项


# 解码器

# 最后的Linear和Softmax层


# 训练概要


# 损失函数




# 参考

* [Transformer的一家](https://mp.weixin.qq.com/s/ArzUQHQ-imSpWRPt6XG9FQ)
* [Transformer](https://mp.weixin.qq.com/s?__biz=MzUyNzA1OTcxNg==&mid=2247486160&idx=1&sn=2dfdedb2edbca76a0c7b110ca9952e98&chksm=fa0414bbcd739dad0ccd604f6dd5ed99e8ab7f713ecafc17dd056fc91ad85968844e70bbf398&scene=178&cur_album_id=1577157748566310916#rd)
* [Hugging Face](https://huggingface.co/docs/transformers/quicktour)
* [🤗 Transformers 教程：pipeline一键预测](https://mp.weixin.qq.com/s/1dtk5gCa7C-wyVQ9vIuRYw)

