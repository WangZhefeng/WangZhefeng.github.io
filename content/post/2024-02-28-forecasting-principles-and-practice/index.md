---
title: 预测：方法与实践
author: 王哲峰
date: '2024-02-28'
slug: forecasting-principles-and-practice
categories:
  - timeseries
tags:
  - book
---

<style>
details {
    border: 1px solid #aaa;
    border-radius: 4px;
    padding: .5em .5em 0;
}
summary {
    font-weight: bold;
    margin: -.5em -.5em 0;
    padding: .5em;
}
details[open] {
    padding: .5em;
}
details[open] summary {
    border-bottom: 1px solid #aaa;
    margin-bottom: .5em;
}
img {
    pointer-events: none;
}
</style>

<details><summary>目录</summary><p>

- [预测](#预测)
    - [什么是可以被预测的？](#什么是可以被预测的)
        - [可预测性需要满足的条件](#可预测性需要满足的条件)
        - [如何准确预测](#如何准确预测)
        - [预测方法的选择](#预测方法的选择)
    - [预测什么？](#预测什么)
        - [预测时长](#预测时长)
        - [预测需要多频繁](#预测需要多频繁)
        - [预测需要的数据](#预测需要的数据)
    - [预测数据和方法](#预测数据和方法)
        - [定性预测方法](#定性预测方法)
        - [定量预测方法](#定量预测方法)
        - [时间序列预测](#时间序列预测)
        - [预测变量和时间序列预测](#预测变量和时间序列预测)
    - [预测过程的主要步骤](#预测过程的主要步骤)
        - [定义问题](#定义问题)
        - [收集信息](#收集信息)
        - [初步探索性分析](#初步探索性分析)
        - [选择及拟合模型](#选择及拟合模型)
        - [使用及评估预测模型](#使用及评估预测模型)
    - [统计预测观点](#统计预测观点)
        - [区间预测与点预测](#区间预测与点预测)
        - [预测分布](#预测分布)
- [时间序列数据探索性分析](#时间序列数据探索性分析)
- [时间序列分解](#时间序列分解)
    - [变换和调整](#变换和调整)
        - [日历调整](#日历调整)
        - [人口调整](#人口调整)
        - [通货膨胀调整](#通货膨胀调整)
        - [数学变换](#数学变换)
            - [对数变换](#对数变换)
            - [幂变换](#幂变换)
            - [Box-Cox 变换族](#box-cox-变换族)
    - [时间列成分](#时间列成分)
        - [加法分解](#加法分解)
        - [乘法分解](#乘法分解)
        - [季节调整数据](#季节调整数据)
    - [移动平均](#移动平均)
        - [平滑移动平均](#平滑移动平均)
        - [移动移动平均](#移动移动平均)
        - [用季节数据估计趋势-周期项](#用季节数据估计趋势-周期项)
        - [加权移动平均](#加权移动平均)
    - [经典时间序列分解](#经典时间序列分解)
        - [加法分解](#加法分解-1)
        - [乘法分解](#乘法分解-1)
    - [经典时间序列分解法评价](#经典时间序列分解法评价)
    - [官方统计机构使用的分解法](#官方统计机构使用的分解法)
    - [STL 分解法](#stl-分解法)
- [时间序列特征](#时间序列特征)
    - [简单的统计描述](#简单的统计描述)
    - [ACF 特征](#acf-特征)
    - [STL 特征](#stl-特征)
    - [其他特征](#其他特征)
- [预测工具集](#预测工具集)
    - [规整的预测工作流程](#规整的预测工作流程)
    - [一些简单的预测方法](#一些简单的预测方法)
        - [均值法](#均值法)
        - [朴素方法](#朴素方法)
        - [季节性朴素方法](#季节性朴素方法)
        - [漂移法](#漂移法)
    - [拟合值与残差](#拟合值与残差)
        - [拟合值](#拟合值)
        - [残差](#残差)
- [判断预测](#判断预测)
- [时间序列回归模型](#时间序列回归模型)
    - [线性模型](#线性模型)
        - [简单线性回归](#简单线性回归)
        - [多元线性回归](#多元线性回归)
        - [假设条件](#假设条件)
    - [最小二乘估计](#最小二乘估计)
        - [模型拟合](#模型拟合)
        - [拟合值](#拟合值-1)
        - [拟合优度](#拟合优度)
        - [回归的标准误差](#回归的标准误差)
    - [回归模型的评估](#回归模型的评估)
        - [残差的性质](#残差的性质)
        - [残差时序图](#残差时序图)
        - [残差的自相关函数图](#残差的自相关函数图)
        - [残差直方图](#残差直方图)
        - [预测变量与残差的关系图](#预测变量与残差的关系图)
        - [拟合值与残差的关系图](#拟合值与残差的关系图)
        - [异常值点和强影响点](#异常值点和强影响点)
        - [伪回归](#伪回归)
    - [回归模型特征构建](#回归模型特征构建)
        - [趋势](#趋势)
        - [虚拟变量](#虚拟变量)
        - [季节性虚拟变量](#季节性虚拟变量)
        - [干预变量](#干预变量)
        - [交易日](#交易日)
        - [分布滞后](#分布滞后)
        - [复活节](#复活节)
        - [傅里叶级数](#傅里叶级数)
    - [预测变量的筛选](#预测变量的筛选)
    - [回归预测](#回归预测)
    - [非线性回归](#非线性回归)
    - [相关关系、因果关系和预测](#相关关系因果关系和预测)
    - [矩阵方程](#矩阵方程)
- [指数平滑](#指数平滑)
    - [简单的指数平滑](#简单的指数平滑)
        - [加权平均形式](#加权平均形式)
        - [分量形式](#分量形式)
    - [趋势性方法](#趋势性方法)
    - [季节性方法](#季节性方法)
    - [指数平滑法的分类](#指数平滑法的分类)
    - [新息指数平滑状态空间模型](#新息指数平滑状态空间模型)
    - [模型估计和选择](#模型估计和选择)
    - [使用 ETS 模型预测](#使用-ets-模型预测)
- [AIRMA 模型](#airma-模型)
    - [平稳性和差分](#平稳性和差分)
        - [平稳性](#平稳性)
        - [差分](#差分)
        - [随机游走](#随机游走)
            - [随机游走模型](#随机游走模型)
            - [带漂移的随机游走模型](#带漂移的随机游走模型)
    - [二阶差分](#二阶差分)
    - [季节性差分](#季节性差分)
- [动态回归模型](#动态回归模型)
- [预测分层或分组时间序列](#预测分层或分组时间序列)
- [高级预测方法](#高级预测方法)
- [实际预测问题](#实际预测问题)
- [参考](#参考)
</p></details><p></p>

# 预测

## 什么是可以被预测的？

### 可预测性需要满足的条件

事件（或数量）的可预测性取决于一下几个因素：

1. 我们对它的影响因素的了解程度；
2. 有多少历史数据是可用的；
3. 未来与过去的相似程度；
4. 预测是否会影响我们试图预测的事物。

例如，对居民用电需求可以非常准确地预测，因为通常这四个条件都可以满足的：

1. 我们很好地了解它的影响因素：电力需求很大程度上受温度影响，也受日期（如假期）和经济状况的影响；
2. 通常我们可以获得过去几年的电力需求数据，以及过去几十年的天气状况数据；
3. 对于短期预测（几周内），可以假设未来的需求行为将与过去是类似的；
4. 对于大多数住宅用户来说，电价不依赖于需求，因此需求预测对消费者行为几乎没有影响。

### 如何准确预测

通常在预测中关键的一步是知道什么情形下能够进行准确预测，确定什么时候预测还不如抛个硬币来的准确。
好的预测可以捕捉到历史数据中的真实模式和关系，而不是重复过去发生过未来不会再发生的事情。

* 如何区分应该忽略的历史数据中的随机波动，和历史数据中应该建模推断的真实模式。
* 一个预测模型的目的是捕捉事物变化的方式，而不仅仅是找到事物在什么位置。

### 预测方法的选择

预测方法的选择取决于什么数据可用和被预测变量的可预测性。

* 朴素方法：使用最近一次观测作为预测
* 判断性预测
* ...

## 预测什么？

在预测的初期阶段，需要决定应该预测的内容。例如，如果生产中的物料需要预测，应该探究以下问题是否要预测：

1. 用于每条产品线或一组产品？
2. 用于每个销售网点，或按区域分组的网点，或仅用于总销售额？
3. 周度数据、月度数据或年度数据？

在进行预测时，应该花时间与使用预测者进行交流，以确保你了解他们的需求并知道预测会被如何使用，
然后再进行扩展性的工作。

### 预测时长

考虑预测的前景时段也十分必要。是需要提前 1 个月，提前 6 个月还是提前 10 年预测？
根据哪个预测时长最为重要，我们需要不同种类的模型。

预测应该是说管理决策中的一个主要组成部分，因为它在企业的很多地方都发挥着重要作用。
现代企业组织需要短期、中期和长期预测，具体预测什么取决于特定的应用场景。

* 短期预测

人员、生产和运输的安排调度需要短期预测。作为安排过程中的一部分，需求预测常常也是必须的。

* 中期预测

确定未来的资源需求需要中期预测，以便购买原材料、雇用人员或购买机器和设备。

* 长期预测

在战略规划中会使用长期预测。此类决定必须将市场机会、环境因素和内部资源纳入考量。

### 预测需要多频繁

需要经常进行的预测，最好是使用自动化系统，而不是需要仔细人工操作。

### 预测需要的数据

一旦确定了所需的预测，则需要查找或收集预测所基于的数据。预测所需的数据可能已经存在了。
近年来，大量的数据被记录，而预测者的任务往往是确定所需数据的存储位置和方式。
数据可能会包括公司的销售记录、产品的历史需求或地理区域的失业率。在制定合适的预测方法之前，
预测者大一部分的时间将用于寻找和整理可用数据。

## 预测数据和方法

在大程度上，什么数据是可用的决定了适合什么合适的预测方法。

### 定性预测方法

如果没有可用的数据，或者如果可用的数据与预测无关，那么应该使用 <span style='border-bottom:1.5px dashed red;'>定性预测</span> 方法。
这些方法不是纯粹的猜测—有完善的结构化方法来获得良好的预测，而不使用历史数据。

### 定量预测方法

在满足以下两个条件的时候可以使用 <span style='border-bottom:1.5px dashed red;'>定量预测</span>：

1. 关于过去的数字化信息是可以用的；
2. 有理由假设过去的一些模式会在未来延续下去。

有各种各样的定量预测方法，这些方法通常是在特定的学科范围为特定的目的而开发的。
每一种方法都有自己的属性、精度和成本，这些应该在方法选择时考虑到。

大多数定量预测问题都使用 <span style='border-bottom:1.5px dashed red;'>时间序列数据</span> (按时间间隔定期收集) 或 <span style='border-bottom:1.5px dashed red;'>横截面数据</span> (在一个时间点收集)。
这里，我们只关注预测未来的数据，并且我们主要专注于时间序列领域。

### 时间序列预测

任何按照时间顺序观察的事物都是时间序列。
我们将只考虑定期观察的时间序列 (例如，每小时、每天、每周、每月、每季度、每年)。
不规则间隔时间序列也可能出现，目前暂不考虑。

最简单的时间序列预测方法只用了预测变量的信息，而不去寻找影响预测变量的因素。
因此，这些方法可以推断趋势部分和季节性部分，但是它们会忽略掉所有其他的信息，
如营销计划，竞争对手活动，经济状况变动等。

### 预测变量和时间序列预测

通常预测变量在时间序列预测中是有用的。例如，假设我们想要预测炎热地区夏季时每小时用电需求量。
可以用如下包含预测变量的模型：

`$$ED = f(当前气温，经济实力，人口当日时间，星期几，误差)$$`

这种关系并不确切–总会有不能由预测变量决定的电力需求变化。
右侧的“误差”项表示随机波动和没有被包括在模型中的相关变量的影响。
我们将它称之为可解释模型，因为它帮助解释电力需求变化的原因。

---

因为电力需求数据构成了一组时间序列，我们也可以用一个时间序列模型来进行预测。
在这种情况下，一个合适的时间序列模型可以为如下形式：

`$$ED_{t+1}=f(ED_{t}，ED_{t-1}，ED_{t-2}，ED_{t-3}，\cdots，误差)$$`

`$t$` 表示当前得时间，`$t+1$` 表示下一个小时，`$t-1$` 表示前一个小时，`$t-2$` 表示前两个小时，以此类推。
此处，对未来的预测是基于变量得过去值，而不是基于可能影响系统得外部变量。
同样，右侧得“误差”项允许随机波动和不包含在模型中的相关变量的影响。

---

还有第三种模型，它结合了上述两种模型的特定。例如，它可能有如下形式：

`$$ED_{t+1}=f(ED_{t}，当前气温，当前时间，星期几，误差)$$`

这些类型的“混合模型”在不同的学科中给出了不同的名称。它们被称为动态回归模型、面板数据模型、纵向模型。
传递函数模型和线性系统模型（假设 `$f$` 是线性的）。

解释模型非常有用，因为它包含了有关其他变量的信息，而不仅仅是要预测的变量的历史值。
但是，预测者可能选择时间序列模型而不是解释性或混合模型的原因有多种：

* 首先，这一系统可能不被理解，即使被理解，也很难衡量被认为应该管理行为的关系；
* 其次，有必要知道或预测各种预测因子的未来价值，以便能够预测有意义的变量，但是这可能太难了；
* 第三，可能主要只是关注预测会发生什么，而不知道为什么会发生；
* 最后，时间序列模型可以提供比解释或混合模型更准确的预测。

在预测中使用的模型取决于可用的资源和数据、模型的准确性以及预测模型的使用方式。

## 预测过程的主要步骤

### 定义问题

通常这是预测中最困难的步骤。要准确定义这个问题，需要了解怎样运用预测方法，谁需要这个预测，
以及预测效果如何满足需要这个预测的机构。预测人员需要花费一定时间与所有参与收集数据、
维护数据库和使用这个预测对未来进行规划的人沟通。

### 收集信息

一般至少需要两种信息收集方式：

1. 统计数据
2. 收集数据和进行预测方面专家的积累经验

通常情况下，要获得足够多的历史数据以构建良好的统计模型是很困难的。
在这种情况下，可以使用判断预测方法。有时候，陈旧数据会因相应数据发生结构变化而失效，
因而我们一般只选择使用较新的数据。然而，一个好的统计模型可以处理系统中的结构变化，
因此不要轻易丢弃好的数据。

### 初步探索性分析

* 总是以图形开头。
* 有一致的模式吗？
* 有明显的长期趋势吗？
* 季节性重要吗？
* 是否有证据表明商业周期存在？
* 数据中是否包含需要专业知识解释的异常值？
* 用于分析的变量之间的相关性有多强？

### 选择及拟合模型

最佳模型的选择取决于历史数据的可用性、预测变量与各解释变量之间的相关性，以及预测的使用方式。
比较两个或三个潜在的模型是很常见的。每个模型本身都基于人为提出的一组假设(显式和隐式)而建立，
通常包含一个或多个参数，这些参数必须使用已知的历史数据进行估计。

常用统计学模型：

* 回归模型
* 指数平滑方法
* Box-Jenkins ARIMA 模型
* 动态回归模型
* 分层预测
* 其他：计数时间序列、神经网络、向量自回归

### 使用及评估预测模型

一旦模型及其参数确定后，该模型就可以用来进行预测。
模型的预测效果只有用于预测的数据得到之后才能得到正确的评价。
目前已经开发了许多方法来评估预测的准确性。在使用和进行预测时会存在很多组织结构问题。
当在实践中使用预测模型时，会出现许多实际问题，例如如何处理缺失值和异常值，或者如何处理短时间序列。

## 统计预测观点

### 区间预测与点预测

我们试图预测的东西是未知的（或者我们不能预测它），所以我们可以把它想象成一个 <span style='border-bottom:1.5px dashed red;'>随机变量</span>。
例如，下个月的总销售额可能会有一系列的可能值，直到月底我们把实际销售额加起来，我们才知道这个值会是多少。
所以在我们知道下个月的销售情况之前，这是一个随机的变量。

因为下个月时间节点比较近，我们通常清楚销售量大概是多少。如果我们预测明年同一个月的销售情况，
可能的销售量变动就会较大。在大多数预测情况下，随着事件的临近，预测对象的相关变动较小。
换句话说，<span style='border-bottom:1.5px dashed red;'>预测的越早，预测结果越不稳定</span>。

我们进行预测的过程实际是寻找随机变量可能取值范围内的中间值。通常情况下，预测会伴随着一个 <span style='border-bottom:1.5px dashed red;'>预测区间</span>，
给出一个随机变量具有较高概率的范围值。例如，95% 的预测区间包含一系列的值，这个预测区间包含实际未来值的概率为 95%。

我们通常会给出这些预测区间，而不是下图中显示的单个可能的预测值。
下面的图表显示了未来澳大利亚国际游客的 80% 和 95% 的预测区间。
蓝线是可能的预测值的平均值，我们称之为 <span style='border-bottom:1.5px dashed red;'>点预测</span>。

![img](images/aus.png)

### 预测分布

使用下标 `$t$` 作为时间。例如，`$y_{t}$` 表示时间 `$t$` 对应的观察值。假设将观察到的所有信息表示为 `${\cal I}$`，
目标是预测 `$y_{t}$`。此时，我们将 `$y_{t}|{\cal I}$` 表示为“给定已知 `${\cal I}$`” 情况下的随机变量 `$y_{t}$`。
这个随机变量取值的概率测度称为 `$y_{t}|{\cal I}$` 的“概率分布”。在预测中，我们称之为 <span style='border-bottom:1.5px dashed red;'>预测分布</span>。

每当我们谈到“预测”时，通常指的是预测分布的平均值，用 `$\hat{y}_{t}$` 来表示 `$y_{t}$` 的预测值，
这意味着 `$y_{t}$` 所有可能取值的均值包含了我们所有已知的信息。

明确指出我们在进行预测时使用的信息时很必要的。
例如，我们使用 `$\hat{y}_{t|t-1}$` 表示在已知观测值 `$(y_{1}，\cdots，y_{t-1})$` 的情况下 `$y_{t}$` 的预测值。
类似地，我们使用 `$\hat{y}_{T+h|T}$` 表示在已知观测值 `$y_{1}，\cdots，y_{T}$` 的情况下 `$y_{T+h}$` 的预测值（即考虑时间 `$T$` 之前所有观测值的 `$h$` 步预测）。

# 时间序列数据探索性分析

> 时间序列图形：开展一切数据分析工作的首要任务是数据可视化。图示化数据可以清晰地呈现数据的特征，包括数据的形态、异常值、随时间变化情况以及变量间的相互关系。我们在预测时应尽可能地将图中显示的特征纳入考虑。正如数据类型会决定所使用的预测方法一样，数据类型也决定了使用什么图形来展示数据。


# 时间序列分解

时间序列数据通常有很多种潜在模式，因此一种有效的处理时间序列的方式是将其分解为多个成分，
其中每个成分都对应一种基础模式。

一般有三种基础的时间序列模式：趋势性，季节性和周期性。当我们想要把时间序列分解为多个成分时，
我们通常将趋势和周期组合为 <span style='border-bottom:1.5px dashed red;'>趋势-周期项（有时也简单称其为趋势项）</span>，因此，我们认为时间序列包括三个成分：<span style='border-bottom:1.5px dashed red;'>趋势-周期项</span>，<span style='border-bottom:1.5px dashed red;'>季节项</span> 和 <span style='border-bottom:1.5px dashed red;'>残差项</span>（残差项包含时间序列中其它所有信息）。
对于不同的季节时期，某些时间序列（例如，至少每日都观测的序列）可能有不止一个季节成份。
我们主要介绍从时间序列中提取成分的常用方法，进而更好的理解时间序列的特点，
并以此提高时间序列的预测精度。

分解时间序列时，首先要使变换或调整序列以使分解尽可能简单（随后的分析也要尽可能简单）。
因此，我们从变换和调整开始讨论。

## 变换和调整

调整历史数据通常可以产生更简单的时间序列。这里，
我们进行四种调整：日历调整、人口调整、通货膨胀调整和数学变换。
这些调整和变换的目的是通过 <span style='border-bottom:1.5px dashed red;'>消除来源已知的波动</span>、
或者 <span style='border-bottom:1.5px dashed red;'>使整个数据集的特征更加一致</span>，达到 <span style='border-bottom:1.5px dashed red;'>简化历史数据特征</span> 的目的。

> 更简单的特征通常更容易建模，产生的预测也更准确。

### 日历调整

季节性数据中出现的一些变化可能是由于简单的日历影响。在这种情况下，在进行进一步分析之前，消除这些变化通常更为容易。

例如，如果你正在研究零售店的月度总销售额，除了一年中的季节性波动外，
由于 <span style='border-bottom:1.5px dashed red;'>每个月的交易天数不同</span>，
月度销售额也会有变化。通过计算每个月 <span style='border-bottom:1.5px dashed red;'>每个交易日的平均销售额</span>，而不是 <span style='border-bottom:1.5px dashed red;'>当月的总销售额</span>，
很容易消除由于每月天数不同引起的变化。通过这种方法我们有效地消除了日历变化。

### 人口调整

任何受人口变化影响的数据都可以调整为人均数据。
即考虑每人平均（或每千人平均，或每百万人平均）的数据，而不是总数。

```r
library(fpp3)
library(tibble)

# GDP
global_economy |>
    filter(Country == "Australia") |>
    autoplot(GDP) +
    labs(title= "GDP"，x = '年份'，y = "$美元")

# 人均 GDP
global_economy |>
    filter(Country == "Australia") |>
    autoplot(GDP/Population) +
    labs(title= "人均GDP"，x = '年份'，y = "$美元")
```



### 通货膨胀调整

受货币价值影响的数据最好在建模前进行调整。比如，如果要比较前后 20 年的同一贩子的价格，
需要通过调整时间序列，将房价调整到同一时期的价格表示。一般通过价格指数进行调整，
一个常见的价格指数就是消费者价格指数（CPI）。

### 数学变换

如果数据显示的变化随着序列的级别增加或减少，那么数学变换可能很有用。

#### 对数变换

通常可以使用对数变换。如果我们将原始观测值表示为 `$y_{1}，\cdots，y_{T}$`，
并且将变换后的观测值表示为由 `$w_{1}，\cdots，w_{T}$`，则 `$w_{T}=log(y_{T})$`。
对数很好用，因为它们是可解释的：对数值的变化可以表示为原始刻度的相对（或百分比）变化。
因此，如果使用的对数基数为 10，那么在对数标度上增加 1 对应于在原始标度上乘以 10。
如果原始序列有零或负值，则不能求对数。

#### 幂变换

有时也会使用其他数学变换（尽管它们可解释度较低）。例如，我们可以使用平方根和立方根。
这些被称为幂变换，因为它们可以写成 `$w_{t}=y_{t}^{P}$` 的形式。

#### Box-Cox 变换族

之前已经有过介绍：[数值特征中的 Box-Cox 变换](https://wangzhefeng.com/note/2022/09/13/feature-engine-type-numeric/#box-cox-%E8%BD%AC%E6%8D%A2)

一个有用的变换族 Box-Cox 变换族，包括对数变换和幂变换，
它取决于参数 `$\lambda$`，定义如下：

`$$w_{t}=\begin{cases}
log(y_{t})，& \lambda = 0 \\
\frac{\Big(sign(y_{t})|y_{t}|^{\lambda}-1\Big)}{\lambda}，& \lambda \neq 0
\end{cases}$$`

<!-- 或者：

`$$y = \begin{cases} 
ln(x)，& \lambda = 0 \\
\frac{(x^\lambda-1)}{\lambda}，& \lambda \neq 0
\end{cases}$$` -->

这实际上是一个修改的 Box-Cox 变换，在 Bickel & Doksum(1981) 中讨论过，
当 `$\lambda>0$` 时允许 `$y_{t}$` 是负值。

Box-Cox 变换中的对数总是自然对数（即以 `$e$` 为对数底）。因此：

* 如果 `$\lambda=0$`，则使用自然对数
* 如果 `$\lambda\neq 0$`，将使用幂变换，然后进行一些缩放
* 如果 `$\lambda=1$`，则 `$w_{t}=y_{t}-1$`，因此变换后的数据向下移动，
  但时间序列的形式没有变化
* 对于 `$\lambda$` 的所有其他值，时间序列将改变形状

合理选择 `$\lambda$` 值可以使整个序列的季节变化大小大致相同，这会使预测模型更简单。
在这种情况下，令 `$\lambda = 0.10$` 效果很好，
尽管 `$\lambda$` 的任何值在 `$0.0$` 和 `$0.2$` 之间都会产生类似的结果。

## 时间列成分

### 加法分解

假设一条时间序列是由多种成分相加得来的，那么它可以写为如下形式：

`$$y_{t}=S_{t}+T_{t}+R_{t}$$`

其中：

* `$y_{t}$` 是时间序列数据
* `$S_{t}$` 表示季节成分
* `$T_{t}$` 表示趋势-周期项
* `$R_{t}$` 表示残差项

### 乘法分解

此外，时间序列也可以写成相乘的形式：

`$$y_{t} = S_{t} \times T_{t} \times R_{t}$$`

如果季节性波动的幅度或者趋势周期项的波动不随时间序列水平的变化而变化，
那么加法模型是最为合适的。当季节项或趋势周期项的变化与时间序列的水平成比例时，
则乘法模型更为合适。在经济时间序列中，乘法模型较为常用。
使用乘法分解的一种替代方法是：首先对数据进行变换，
直到时间序列随时间的波动趋于稳定，然后再使用加法分解。
显然，采用对数变换的加法模型等价于乘法模型：

`$$y_{t} = S_{t} \times T_{t} \times R_{t}$$`

等价于

`$$log y_{t} = log S_{t} + log T_{t} + log R_{t}$$`

### 季节调整数据

如果将季节项从原始数据中剔除，可以得到经过”季节调整”后的数据。
对于加法分解，季节调整数据的表达式为：
`$y_{t} - S_{t}$`，对于乘法分解，季节调整数据可以表示为：`$y_{t}/S_{t}$`。

如果我们关心的不是季节性的数据波动，那么季节调整后的时间序列就会十分有用。

例如，每月的失业率会受到季节性因素的影响，在学生离校的时期，当月失业率会显著上升，
但这种失业率并不是由于经济衰退而导致的。因此，当研究经济和失业率的关系时，
应该将失业率进行季节调整。大多数研究实业数据的经济分析学者对非季节性变化更感兴趣。
因此，就业数据（和很多其他的经济数据）通常会经过季节调整。

经过季节调整后的时间序列既包含残差项也包含趋势周期项。因此，它们不太”平滑”，
其”下转折”和”上转折”可能会有误导性。如果我们的目的是找到序列的转折点并解释方向的变化，
那么相比于用季节调整后的数据，用趋势-周期项会更合适。

## 移动平均

时间序列分解的经典方法起源于 20 世纪 20 年代，直到 20 世纪 50 年代才被广泛使用。
它仍然是许多时间序列分解方法的基础，因此了解它的原理十分重要。
传统的时间序列分解方法的第一步是用移动平均的方法估计趋势-周期项。

### 平滑移动平均

`$m$` 阶移动平均可以被写为：

`$$\hat{T}_{t} = \frac{1}{m}\sum_{j=-k}^{k}y_{t+j}$$`

上式中 `$m=2k+1$`，也能是说，
时间点 `$t$` 的趋势-周期项的估计值是通过求 `$t$` 时刻 `$k$` 周期内的平均得到的。
时间临近的情况下，观测值也很可能接近。由此，平均值消除了数据中的一些随机性，
得到较为平滑的趋势周期，我们称它为 `$m-MA$`，也就是 `$m$` 阶移动平均。

移动平均的阶数决定了趋势-周期项的平滑程度。一般情况下，阶数越大曲线越平滑。

简单移动平均的阶数常常是奇数阶（例如：3，5，7等），这样可以确保对称性。
在阶数为 `$m=2k+1$` 的移动平均中，中心观测值和两侧各有的 `$k$` 个观测值可以被平均。
但是如果 `$m$` 是偶数，那么它就不再具备对称性。

### 移动移动平均

### 用季节数据估计趋势-周期项


### 加权移动平均



## 经典时间序列分解

经典时间序列分解法起源于20世纪20年代。它的步骤相对简单，它是很多其他的时间序列分解法的基石。
有两种经典时间序列分解法：加法分解和乘法分解。

下面将描述一个季节周期为 `$m$` 的时间序列（例：`$m=4$` 的季度数据，`$m=12$` 的月度数据， 
`$m=7$` 的周度数据）。

在经典时间序列分解法中，我们假设季节项每年都是连续的。对于乘法季节性，
构成季节项的 `$m$` 个值被称为季节指数。

### 加法分解

* 步骤1：若 `$m$` 为偶数，用 `$2\times m-MA$` 来计算趋势周期项 `$\hat{T}_{t}$`。
  若 `$m$` 为奇数，用 `$m-MA$` 来计算趋势周期项 `$\hat{T}_{t}$`。
* 步骤2：计算去趋势序列：`$y_{t}-\hat{T}_{t}$`。
* 步骤3：为了估计每个季度的季节项，简单平均那个季度的去趋势值。例如，对于月度数据，
  三月份的季节项是对所有去除趋势后的三月份的值的平均。然后将这些季节项进行调整，
  使得它们的加和为 0。季节项是通过将这些各年的数据排列结合在一起而得到的，
  即  `$\hat{S}_{t}$`。
* 步骤 4：残差项是通过时间序列减去估计的季节项和趋势-周期项求得的：`$\hat{R}_{t}=y_{t}-\hat{T}_{t}-\hat{S}_{t}$`。

### 乘法分解

经典乘法分解与加法分解十分相似，只不过是用除法代替了减法。

* 步骤 1：若 `$m$` 为偶数，用 `$2\times m-MA$` 来计算趋势周期项 `$\hat{T}_{t}$`。
  若 `$m$` 为奇数，用 `$m-MA$` 来计算趋势周期项 `$\hat{T}_{t}$`。
* 步骤 2：计算去趋势序列：`$y_{t}-\hat{T}_{t}$`。
* 步骤 3：为了估计每个季度的季节项，简单平均那个季度的去趋势值。
  例如，对于月度数据，三月份的季节项是对所有去除趋势后的三月份的值的平均。
  然后将这些季节项进行调整，使得它们的加和为 `$m$`。
  季节项是通过将这些各年的数据排列结合在一起而得到的，即 `$\hat{S}_{t}$`。
* 步骤 4：残差项是通过时间序列除以估计的季节项和趋势-周期项求得的：`$\hat{R}_{t}=y_{t}/(\hat{T}_{t}\hat{S}_{t})$`。

## 经典时间序列分解法评价

尽管经典时间序列分解法的应用还很广泛，但是我们不十分推荐使用它，因为现在已经有了一些更好的方法。
经典时间序列分解的几点问题总结如下：

1. 经典时间序列分解法无法估计趋势-周期项的最前面几个和最后面几个的观测。例如，若 `$m=12$`，
   则没有前六个或后六个观测的趋势-周期项估计。由此也会使得相对应的时期没有残差项的估计值。
2. 经典时间序列分解法对趋势-周期项的估计倾向于过度平滑数据中的快速上升或快速下降（如上面例子中所示）。
3. 经典时间序列分解法假设季节项每年是重复的。对于很多序列来说这是合理的，但是对于更长的时间序列来说这还有待考量。
   例如，因为空调的普及，用电需求模式会随着时间的变化而变化。具体来说，在很多地方几十年前的时候，
   各个季节中冬季是用电高峰（用于供暖加热），但是现在夏季的用电需求最大（由于开空调）。
   经典时间序列分解法无法捕捉这类的季节项随时间变化而变化。
4. 有时候，时间序列中一些时期的值可能异乎寻常地与众不同。例如，每月的航空客运量可能会受到工业纠纷的影响，
   使得纠纷时期的客运量与往常十分不同。处理这类异常值，经典时间序列分解法通常不够稳健。

## 官方统计机构使用的分解法


## STL 分解法


# 时间序列特征

## 简单的统计描述

## ACF 特征

## STL 特征

## 其他特征

# 预测工具集

## 规整的预测工作流程

为时间序列数据生成预测的过程可以分解为几个步骤：

![img](images/tools.png)

1. 数据准备--整理

预测的第一步是以正确的格式准备数据。
此过程可能涉及加载数据、识别缺失值、过滤时间序列和其他预处理任务。

许多模型有不同的数据要求； 有些要求序列按时间顺序排列，有些则要求没有缺失值。
检查数据是了解其特征的重要步骤，应始终在估计模型之前完成。

2. 数据可视化--可视化

可视化是理解数据的重要步骤。 查看您的数据可以让您识别常见模式，然后指定合适的模型。

3. 定义模型--指定

有许多不同的时间序列模型可用于预测，为数据指定适当的模型对于生成适当的预测至关重要。

4. 训练模型--估计

一旦指定了合适的模型，接下来我们将在一些数据上训练模型。

5. 检查模型性能--评估

拟合模型后，重要的是检查它对数据的执行情况。 有多种诊断工具可用于检查模型行为，
以及允许将一个模型与另一个模型进行比较的准确性度量。

6. 产生预测--预测

指定、估计和检查了适当的模型后，就可以生成预测了。

在其他情况下，提供未来时间段的数据集进行预测可能更方便。
当您的模型使用数据中的附加信息(例如外生回归变量)时，通常需要这样做。
模型所需的额外数据可以包含在要预测的观测数据集中。

## 一些简单的预测方法

一些预测方法虽然简单但非常有效。下面介绍的这四种预测方法可以作为预测的基准方法。

有时候这些最简单的方法可能会是最好的预测方法，但是在很多情况下，
这些方法只是作为基准方法而不是被直接运用。
也就是说，我们提出的任何预测方法都会和这些简单方法比较，
以保证其预测结果优于这些简单方法，否则，新的方法就不值得考虑。

### 均值法

此方法中，所有未来值的预测值等于历史数据的平均值。我们把历史数据记作：`$y_{1}，\cdots，y_{T}$`，
预测值就可以表示为：

`$$\hat{y}_{T+h|T}=\bar{y}=\frac{(y_{1} + \cdots + y_{T})}{T}$$`

其中：

* `$\hat{y}_{T+h|T}$` 代表 `$y_{1}，\cdots，y_{T}$` 对 `$y_{T+h}$` 的估计值

### 朴素方法

> Naïve 方法

在朴素预测方法中，我们简单地将所有预测值设为最后一次的观测值，即：

`$$\hat{y}_{T+h|T} = y_{T}$$`

这种方法在很多经济和金融时间序列预测中表现得非常好。
当数据服从随机游动过程时 Naïve 预测是最优的，
因此 Naïve 方法也被称为“随机游动预测”。

### 季节性朴素方法

季节性朴素方法与朴素方法类似，它适用于季节性变化剧烈的数据。
我们将每个预测值设为同一季节的前一期观测值（例如：去年的同一个月）。
那么，`$T+h$` 时刻的预测值可以记作：

`$$\hat{y}_{T+h|T}=y_{T+h-m(k+1)}$$`

其中：

* `$m$` 为周期长度
* `$k$` 是 `$(h-1)/m$` 的整数部分（也就是在 `$T+h$` 时刻前预测期所包含的整年数）

这个等式并没有看起来那么复杂，例如，对于月度数据，未来所有二月的预测值都等于前一年二月的观测值。
对于季度数据，未来所有第二季度的预测值都等于前一年第二季度的观测值。
相似的规则适用于其他的月份、季度和其他周期长度。

### 漂移法

相对于朴素方法，漂移法允许预测值随着时间的推移增大或减小，
并且我们假定单位时间改变量（称作“漂移”）等于历史数据的平均改变量，
因此 `$T+h$` 时刻的预测值可以表示为：

`$$\hat{y}_{T+h|T}=y_{T}+\frac{h}{T-1}\sum_{T}^{t=2}(y_{t}-y_{t-1})=y_{T}+ h \Big(\frac{y_{T}-y_{1}}{T-1} \Big)$$`

这相当于把第一个观测点和最后一个观测点连成一条直线并延伸到未来预测点。

## 拟合值与残差

### 拟合值

时间序列中的每个观测值都可以用其之前的观测值预测，我们称其为“拟合值”并记作 `$\hat{y}_{t|t-1}$`，
代表基于观测值 `$y_{1} \cdots，y_{t-1}$` 得出的预测值 `$y_{t}$`，由于经常用到，
有时我们会去掉部分下标并简写成 `$\hat{y}_{t}$`，而不是 `$\hat{y}_{t|t-1}$`，拟合值总是包含到一步预测。

事实上，拟合值通常不是真正的预测值因为包含于预测方法中的任何参数都是利用时间序列中所有可得到的观测值估计出来的，
甚至包括未来观测值。例如，假如我们采用平均方法，拟合值如下给出：

`$$\hat{y}_{t}=\hat{c}$$`

该式中，`$\hat{c}$` 是所有可得观测值的平均值，包括那些在 `$t$` 时间以后的观测值。相似地，
对于趋势法，趋势参数是用所有可得观测值估计出来的，在这种情况下拟合值如下：

`$$\hat{y}_{t}=y_{t-1}\hat{c}$$`，

其中：

`$$\hat{c}=\frac{y_{T}-y_{1}}{T-1}$$`

两种方法中都有参数是用数据估计出来的，`$c$` 上的“帽子”说明它是个估计值，
当 `$c$` 的估计值由包含时间 `$t$` 以后的观测值估计出来时，拟合值不是真正的预测值。
另一方面，Naïve 方法和季节性朴素法不包括任何参数，因此得到的拟合值是真正的预测值。

### 残差

时间序列模型中的残差可以理解为是在拟合模型后剩余的值。残差等于观测值与相应拟合值之间的差值:

`$$e_{t}=y_{t}-\hat{y}_{t}$$`

如果在模型中使用了变换，那么查看变换尺度上的残差通常是有用的。我们称这些为“创新残差”。
例如，假设我们对数据的对数建模 `$w_{t}=log(y_{t})$`。创新残差由 `$w_{t}-\hat{w}_{t}$` 给出，
常规残差由 `$y_{t}-\hat{y}_{t}$` 给出。如果没有使用变换，那么创新残差与常规残差相同，
在这种情况下，我们将简单地称之为“残差”。

残差在检查模型是否充分捕获了数据中的信息时很有用。为此，我们使用创新剩余。
如果在创新残差中可以观察到残差模式，则可能对模型进行改进。

# 判断预测

在实践中，使用判断进行预测非常普遍。在很多情况下，判断预测是唯一的选择。
例如 <span style='border-bottom:1.5px dashed red;'>完全缺乏历史数据时</span>，
新产品上市时，新的竞争对手进入市场时，或者在全新并且独特的市场条件下。
例如，2012年12月，澳大利亚政府首次通过立法禁止在香烟包装上使用公司标识，
并要求所有香烟包装必须为深绿色。由于没有历史先例，所以必须采用判断法来预测这种政策的效果。

还有一些情况是 <span style='border-bottom:1.5px dashed red;'>数据不完整，或者数据获取有一定的滞后</span>。
例如，中央银行在预测当前经济活动水平时会采用判断法，因为 GDP 只能按季度计算，这一过程被称为临近预测。

这个领域的研究已经表明，当预测者拥有：<span style='border-bottom:1.5px dashed red;'>重要的专业知识和</span>、
<span style='border-bottom:1.5px dashed red;'>更及时的最新信息时</span>，判断预测的准确性会提高。
判断方法可以快速适应这些变化、信息或事件。

多年来，人们越来越多地接受判断预测作为一门科学，也越来越认识到它的必要性。更重要的是，判断预测的质量也有所提高，
其直接原因是认识到 <span style='border-bottom:1.5px dashed red;'>通过实施结构完善的系统方法可以实现对判断预测的改进</span>。
需要注意的是，判断预测具有主观性和局限性。
然而，实施系统化和结构完善的方法可以解决这些限制并显着提高预测精度。

一般有三种情况需要使用判断预测：

1. 没有可用数据，因此统计方法不适用，判断预测是唯一可行的方法；
2. 数据可用，先进行统计预测，然后使用判断法进行调整；
3. 数据可用，分别使用统计预测和判断预测，然后将两者进行组合。

需要说明的是，当数据可用时，更倾向于应用统计方法，或者至少应该从统计方法入手。
统计预测通常优于仅使用判断预测。我们将重点讨论第一种没有可用数据的情况。


# 时间序列回归模型

线性回归模型的核心思路是：我们预测时间序列 `$y$` 时假设它与其它时间序列 `$x$` 之间存在线性关系。
例如，我们可以通过广告总花费 `$x$` 来预测月度销量 `$y$`；同样的，
我们可以通过气温数据 `$x_{1}$` 和星期数据 `$x_{2}$` 来预测日耗电量 `$y$`。

* 被预测变量 `$y$` 有时还称作回归变量、因变量或被解释变量。
* 预测变量 `$x$` 有时也叫作回归量、自变量或解释变量。这里我们称它们为“被预测变量”和“预测变量”。

## 线性模型

### 简单线性回归

最简单的线性回归模型假设被预测变量 `$y$` 和单个预测变量 `$x$` 之间存在如下线性关系：

`$$y_{t} = \beta_{0} + \beta_{1}x_{t} + \varepsilon_{t}$$`

观测值并不全部落在回归线上，而是分布在回归线的周围。我们可以这样理解：
每个观测值 `$y_{t}$` 都包含可解释部分 `$\beta_{0}+\beta_{1}x_{t}$` 和随机误差项 `$\varepsilon_{t}$`。
随机误差项并不意味着错误，而是指观测值与线性模型的偏差。
它捕捉到了除 `$x_{t}$` 外其他影响 `$y_{t}$` 的信息。

### 多元线性回归

当预测变量有两个甚至更多时，模型被称为多元线性回归模型。多元线性回归模型的一般形式如下：

`$$y_{t}=\beta_{0}+\beta_{1}x_{1，t}+\beta_{2}x_{2，t}+\cdots+\beta_{k}x_{k，t}+\varepsilon_{t}$$`

其中，`$y$` 是被预测变量，`$x_{1}，\cdots，x_{k}$` 是 `$k$` 个预测变量，
每个预测变量都必须为数值型变量。系数 `$\beta{1}，\cdots，\beta_{k}$` 分别衡量了在保持其他所有预测变量不变的情况下，
该预测变量对被预测变量的影响程度。因此，系数衡量了对应预测变量对被预测变量的边际影响。

### 假设条件

当我们想要使用线性回归模型时，需要对变量做出一些基本假设。

1. 首先，我们假设线性模型是对现实情况的合理近似；也就是说，预测变量和被预测变量之间的关系基本满足这个线性方程。
2. 其次，我们对误差项 `$(\varepsilon_{1}，\cdots，\varepsilon_{T})$` 做出如下假设：
    * 期望为零；否则预测结果会产生系统性偏差。
    * 随机误差项彼此不相关；否则预测效果会很差，因为这表明数据中尚有很多可用信息没有包含在模型中。
    * 与预测变量不相关；若误差项与预测变量相关，则表明模型的系统部分中应该包含更多信息。
    * 为了方便得到预测区间，我们还需要假设随机误差项服从方差为 `$\sigma^{2}$` 的正态分布。

线性回归模型还有一个重要的假设是 <span style='border-bottom:1.5px dashed red;'>预测变量 `$x$` 不是随机变量</span>。在进行模拟实验时，
我们可以控制每个 `$x$` 的值（所以 `$x$` 不会是随机的）并观察 `$y$` 的结果值。
但在实际生活中，我们只能得到观察数据（包括商业和经济学中的大多数数据），
而不能控制 `$x$` 的值。因此，我们需要做出如上假设。

## 最小二乘估计

### 模型拟合

在实际问题中，有一系列的观察值，
但是我们不知道模型系数 `$\beta_{0}, \beta_{1}, \cdots, \beta_{k}$` 的具体值。
因此，我们需要利用模型对这些参数进行估计。

最小二乘估计方法通过最小化残差平方和来确定模型的各个参数。
也就是说，我们通过最小化下式来确定 `$\beta_{0}, \beta_{1}, \cdots, \beta_{k}$`的估计值：

`$$\sum_{t=1}^{T}\varepsilon_{t}^{2}=\sum_{t=1}^{T}(y_{t} - \beta_{0} - \beta_{1}x_{1,t}-\beta_{2}x_{2,t} - \cdots - \beta_{k}x_{k,t})^{2}$$`

由于它的目标是最小化残差平方和，因此被称为最小二乘估计。寻找最优参数的过程，一般被称为“拟合”模型，
或者被称为模型的“学习”或者“训练”。参数估计值，
一般用 `$\hat{\beta}_{0}, \hat{\beta}_{1}, \cdots, \hat{\beta}_{k}$` 来表示。

### 拟合值

可以利用回归方程中的估计系数并将误差项设置为零来预测 `$y$`。我们通常将模型写成如下形式：

`$$\hat{y}_{t}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{1,t}+\cdots+\hat{\beta}_{k}x_{k,t}$$`

将训练样本中 `$x_{1,t}, \cdots, x_{k,t}$`（其中 `$t=1,\cdots, T$`）的值代入模型中，
我们将会得到 `$y_{t}$` 的预测值，即为模型的拟合值。需要注意的是，这是模型估计得到的训练样本的预测值，
而不是 `$y$` 未来真实值的预测值。

### 拟合优度

一般用可决系数 `$R^{2}$` 评价线性回归模型对数据的拟合程度。
它可以通过计算观测值 `$y$` 和预测值 `$\hat{y}$` 之间的相关性来得出。或者，通过下式计算：

`$$R^{2}=\frac{\sum(\hat{y}_{t}-\bar{y})^{2}}{\sum(y_{t}-\bar{y})^{2}}$$`

可决系数反映了回归模型所能解释的被预测变量的变异占被预测变量总变异的比例。

在简单线性回归模型中，`$R^{2}$` 也等于 `$y$` 和 `$x$` 的相关系数的平方（假设存在截距项）。
预测值越接近于真实值，`$R^{2}$` 则会越接近于 `$1$`。
相反，若预测值和真实值不相关，则 `$R^{2}=0$` （假设存在截距项）。
在其它情况下，`$R^{2}$` 的值会处在 `$0$` 和 `$1$` 之间。

但是仅仅利用 `$R^{2}$` 来衡量模型是远远不够的。因为当增加解释变量的个数时，
`$R^{2}$` 值将会不断增加，但这并不意味着更好的模型效果。目前并不存在衡量 `$R^{2}$` 值好坏的规则， 
`$R^{2}$` 值的有效性需要视具体情况而定。
因此，利用模型在测试集上的预测结果来衡量模型好坏比直接根据 `$R^{2}$` 大小来衡量模型更加有效。

### 回归的标准误差

另外一个衡量模型拟合效果的指标是残差的标准偏差，通常称之为“残差标准误差”。
它可以通过下式来计算：

`$$\hat{\sigma}_{e}=\sqrt{\frac{1}{T-k-1}\sum_{t=1}^{T}{e_t^2}}$$`

其中：

* `$k$` 是模型中预测变量的个数
* `$T$` 是样本数量
* `$e_{t}^{2}$` 是模型拟合值 `$\hat{y}$` 和实际观测值 `$y$` 之间的差值，被称为训练误差或“残差”

需要注意的是，由于需要估计的参数个数为 `$k+1$`（截距项和 `$k$` 个解释变量），
因此上式中分母为 `$T-k-1$`。

模型的标准误差和平均误差有一定联系。我们可以将标准误与 `$y$` 的均值或标准差做对比，
得到一些关于模型精度的结论。在生成被预测变量的预测区间时，标准误差将十分有用。

## 回归模型的评估

### 残差的性质

模型拟合值 `$\hat{y}$` 和实际观测值 `$y$` 之间的差值，被称为训练误差或“残差”，其表达式如下：

`$$
\begin{align*}
  e_t &= y_t - \hat{y}_t \\
      &= y_t - \hat\beta_{0} - \hat\beta_{1} x_{1,t} - \hat\beta_{2} x_{2,t} - \cdots - \hat\beta_{k} x_{k,t}
\end{align*}$$`

其中：

* `$t=1,\cdots, T$`
* 每个残差 `$e_{t}$` 都是观测值中不可预测的部分 

残差项有两个非常有用的性质：

`$$\sum_{t=1}^{T}e_{t}=0 \quad and \quad \sum_{t=1}^{T}x_{k,t}e_{t}=0 \quad \text{for all} \quad k.$$` 

从以上两式可以明显看出：

1. 残差的均值为零；
2. 残差项和预测变量之间相关性为零。（当模型中没有截距项时，零相关假设不一定成立。）

在选择回归变量并拟合回归模型之后，有必要绘制残差图以检查模型的假设是否已经满足。
此外应该生成一系列图表，以检查拟合模型的不同方面和基本假设是否成立。下面我们将逐个分析。

### 残差时序图

残差时序图显示了不同时间下的残差的变化，如果残差存在异方差性，这种异方差性会导致预测区间的不准确。

### 残差的自相关函数图

> 残差的自相关函数，简称 ACF

对于时间序列数据而言，在当前时间段观测到的变量值很可能与历史时段的变量值很相似。
因此，当采用回归模型拟合时间序列数据时，残差经常会出现自相关效应。
此时，模型违背了残差中无序列自相关的假设，并会导致模型的预测效率低下。
为了获得更为准确的预测值，在模型中应该考虑更多的信息。当残差项存在序列自相关时，
模型的预测结果仍然是无偏的，但此时得到预测区间范围通常会比我们需要的预测区间范围更大。
因此我们应当重点关注模型残差的 ACF 图。

另一个用于检验残差自相关的效果较好的检验方法是 Breusch-Godfrey 检验，
也被称为 LM （拉格朗日乘数）检验。假如 `$p$` 值小于一个特定值（例如 0.05），
则表明残差中存在显著的自相关性。Breusch-Godfrey 检验类似于 Ljung-Box 检验，
但它是专门用于回归模型的残差检验。

### 残差直方图

检查残差是否服从正态分布也是很有必要的。正如之前我们所解释的一样，
它对预测值并不重要，但它可以让我们更加容易的确定预测区间。

残差直方图显示了残差分布是否存在左偏或右偏，如果存在，则可能影响预测区间的准确度。

### 预测变量与残差的关系图

我们期望残差是随机分布的并且不显示任何规律，
一个简单快捷的检验方法是查看每个预测变量与残差的散点图。
如果这些散点图表现出明显的规律，则该关系可能是非线性的，
并且需要相应地修改模型，可能需要使用非线性模型。

此外，还需要对没有加入到模型中的预测变量绘制其与残差的散点图。
如果某个残差图显示出明显的规律，
则需要将对应的预测变量加入到模型之中（可能以非线性形式加入）。

### 拟合值与残差的关系图

残差与拟合值之间也应没有明显规律。如果观察到明显规律，
则残差中可能存在“异方差性”，这意味着残差的方差不是固定的。
如果出现异方差性，可能需要对预测变量做对数或者平方根变换。

### 异常值点和强影响点

与大多数数据相差甚远的点被称为“异常值点”。
对模型的参数估计有重大影响的观测点被称为“强影响点”。
通常情况下，强影响点在 `$x$` 方向也是极端的异常值。

异常值的一个来源是不正确的数据录入。简单的数据描述性统计可以识别出异常的最小值和最大值。
如果识别出这样的观察结果，则应立即对样本进行校正或删除。

当某些观测点完全不同时，也会出现异常值点。在这种情况下，将这些观测点全部删除是不可取的。
如果观察结果已被确定为异常值，则必须对其进行研究并分析其背后的可能原因。
删除或保留观察可能是一个艰难决定（特别是当异常值是有影响力的观察时）。
因此，可以分别对删除观测值和保留观测值做分析。

### 伪回归

时间序列数据一般都是“不平稳的”；也就是说，时间序列数据没有固定的均值和方差。
因此我们需要解决非平稳数据对回归模型的影响，后面我们会详细讨论时间序列的平稳性。
在这里，我们需要强调非平稳数据对回归模型的影响。

不平稳的时间序列会导致伪回归。
伪回归的特点是高 `$R^{2}$` 值和高残差自相关共存。
伪回归模型似乎可以给出合理的短期预测，
但在长期时间中，伪回归是无效的。

## 回归模型特征构建

> 原来的题目：一些有用的预测变量

### 趋势

很多时间序列存在趋势。当存在简单的线性趋势时，可以直接使用 `$x_{1,t}=t$` 作为预测变量：

`$$y_{t} = \beta_{0} + \beta_{1}t + \varepsilon_{t}$$`

其中：

* `$t = 1, 2, \cdots, T$`

### 虚拟变量

目前，我们讨论的每个预测变量都是数值型变量。
但是当某个预测变量为分类变量且只有两个取值时（例如，“是”或“否”）应当怎么处理？
例如，当你想要预测日销量时，
你想把当天是否为 <span style='border-bottom:1.5px dashed red;'>法定节假日</span> 考虑进来。此时，则需要引入一个预测变量，当天为法定节假日时该变量取值为“是”，否则取值为“否”。

在这种情况下，我们可以通过在多元模型中添加“虚拟变量”来进行处理。
当虚拟变量的取值为 1 时，代表“是”；取值为 0 时代表“否”。
虚拟变量通常也被称为“指示变量”。

虚拟变量也可以用来处理数据中的 <span style='border-bottom:1.5px dashed red;'>离群点</span> 。虚拟变量不会省略异常值，而是会消除其效果。当该观测值是离群点时，虚拟变量取值为 1，
在其他观测值处，虚拟变量取值均为 0。虚拟变量也可以表示特殊事件是否发生。

如果有两个以上的类别，则可以使用多个虚拟变量（需要注意的是，虚拟变量个数应比类别数少1）对变量进行编码。

### 季节性虚拟变量



### 干预变量

建模时，我们通常需要考虑可能对被预测变量的产生影响的干预因素。
例如竞争对手的活动、广告支出、工业行动等等都会对被预测变量产生影响。

* 当干预因素的影响仅持续一个时期时，
  我们可以使用 <span style='border-bottom:1.5px dashed red;'>“尖峰”变量</span> 来描述。
  尖峰变量的处理方法和处理离群点非常相似，也是构造一个虚拟变量，
  在干预因素作用期间取值1，在其他地方取 0。
* 干预因素的影响还可能是长期或永久的。
    - 如果干预因素导致水平偏移（即序列的值从干预时间点之后突然且永久地改变），
      那么我们使用 <span style='border-bottom:1.5px dashed red;'>“阶梯”变量</span>。
      阶梯变量在干预产生之前取值为 0，从干预产生之后取值为 1。
    - 干预因素的另一种长远影响是斜率的变化。
      此时需采取 <span style='border-bottom:1.5px dashed red;'>分段处理</span>，
      在干预因素产生影响前后斜率是不同的，因此模型是非线性的。

### 交易日

一个月的交易日数可能会有很大差异，并会对销售数据产生重大影响。
为此，可以将每个月的交易日数作为预测变量。

对于月度或季度数据，可以计算出每个时期内的交易日数。可以引入 7 个解释变量，每个解释变量定义如下：

`$$x_{1} = \text{当月中周一的数目}$$`
`$$x_{2} = \text{当月中周二的数目}$$`
`$$\cdots$$`
`$$x_{7} = \text{当月中周日的数目}$$`

### 分布滞后

通常情况下，把广告支出作为解释变量会十分有效。但是，广告效应往往会具有滞后性。
因此，我们可以使用如下变量：

`$$x_{1} = \text{一个月前的广告支出}$$`
`$$x_{2} = \text{两个月前的广告支出}$$`
`$$\cdots$$`
`$$x_{m} = \text{m 个月前的广告支出}$$`

一般情况下，系数随着滞后阶数的增加而减小。

### 复活节

复活节与其他大多数的假期不同，因为它不是每年在同一天举行，并且其影响可持续一段时间。
在这种情况下，在复活节特定的时间段内，虚拟变量取值为 1，在其他时间段内取值为 0。
当复活节从 3 月开始到 4 月结束时，虚拟变量在月份之间按比例分配。

当数据为月度数据时，若复活节在三月份，那么虚拟变量在三月份时取 1；
同样的，若复活节在四月份时，虚拟变量在四月份时取 1。
当复活节从 3 月开始到 4 月结束时，虚拟变量在月份之间按比例分配。

### 傅里叶级数












## 预测变量的筛选


## 回归预测


## 非线性回归


## 相关关系、因果关系和预测


## 矩阵方程


# 指数平滑

指数平滑是在 20 世纪 50 年代后期提出的(Brown，1959; Holt，1957; Winters，1960)，
其激发了一些十分成功的预测方法。
<span style='border-bottom:1.5px dashed red;'>使用指数平滑方法生成的预测是过去观测值的加权平均值，
并且随着过去观测值离预测值距离的增大，权重呈指数型衰减。换句话说，观察值越近，相应的权重越高。</span>
该框架能够快速生成可靠的预测结果，并且适用于广泛的时间序列，这是一个巨大的优势并且对于工业应用来说非常重要。

这里分两部分介绍：

* 第一部分介绍了最重要的指数平滑方法的机制，
  以及该方法在预测具有不同特征的时间序列中的应用，
  这有助于我们对这些方法如何运作有一种直观的认识。
  在这种情况下，选择和使用预测方法可能会有点特殊。
  该方法的选择通常基于识别时间序列的关键因素（趋势和季节），
  以及它们应用平滑方法的方式（例如，以加性，阻尼或乘性方式）。
* 第二部分介绍构成指数平滑方法基础的统计模型。
  这些模型与第一部分讨论的方法能够生成相同的点预测，
  同时也能生成预测区间。此外，这个统计框架能在竞争模型之间进行真正的模型选择。

## 简单的指数平滑

最简单的指数平滑方法自然被称为 <span style='border-bottom:1.5px dashed red;'>简单指数平滑(SES)</span>。
这种方法适用于预测没有明显趋势或季节因素的数据。

如果数据中没有显示任何明确的趋势或季节性因素，
应该考虑对这样的数据使用朴素预测和平均法进行预测：

* 使用 <span style='border-bottom:1.5px dashed red;'>朴素法</span>，
  对未来的所有预测都等于该序列的最后一个观测值：

    `$$\hat{y}_{T+h|T}=y_{T}$$`

    其中：`$h=1，2，...$`

    因此，朴素法假设最近的观测值是唯一重要的观测值，并且之前所有的观测值都不提供未来的信息。
    这可以看作是一个加权平均值，其中所有的权重都被赋给了最后一次观测值。

* 使用 <span style='border-bottom:1.5px dashed red;'>平均值</span>，
  所有未来预测值都等于观测数据的简单平均值：

    `$$\hat{y}_{T+h|T}=\frac{1}{T}\sum_{t=1}^{T}y_{t}$$`

    其中：`$h=1，2，...$`

    因此，平均法假设所有观测值具有同等重要性，并在预测时给予相同的权重。

我们经常需要的是在这两个极端方法之间的方法。例如，
可能明智的做法是将更大的权重赋到最近的观测值而不是过去的观测值。
这正是简单指数平滑背后的原理。预测值使用加权平均值进行计算，
其中权重随观测时间的久远程度呈指数型下降——最早的观察值被赋予最小的权值：

`$$\hat{y}_{T+1|T}=\alpha y_{T}+\alpha(1-\alpha)y_{T-1}+\alpha(1-\alpha)^{2}y_{T-2}+\cdots$$`

其中：

* `$0 \leq \alpha \leq 1$` 是平滑参数
* 向前一步 `$T+1$` 时刻的预测值是时间序列 `$y_{1}，\cdots，y_{T}$` 中所有观测值的加权平均值
* 权重下降的速度由参数 `$\alpha$` 控制

下表展示了在使用简单指数平滑进行预测时，
四个不同的 `$\alpha$` 值所对应的观察值的权重。

![img](images/ses.png)

对于任何合理的样本量，即使 `$\alpha$` 数值很小，权重的总和也应该近似为 1。
对于 0 到 1 之间的任何 `$\alpha$` 值，随着时间向前推移，观察值的权重呈指数型下降，
因此我们称之为“指数平滑”。

* 如果 `$\alpha$` 很小（即接近于0），那么更远的过去的观测值会被赋予更多的权重。
* 如果 `$\alpha$` 很大（即接近 1），则赋予更多的权重给最近的观测值。
* 对于 `$\alpha=1$`，`$\hat{y}_{T+1|T}=y_{T}$` 的极端情况，指数平滑的预测值等于朴素预测值。

### 加权平均形式


### 分量形式


## 趋势性方法


## 季节性方法


## 指数平滑法的分类

指数平滑法并不局限于前面的提出的这些方法。通过考虑趋势和季节分量的不同组合变化，
可以得到 9 种指数平滑方法。如果每种方法都由一对字母组合 `$(T，S)$` 标记，
分别表示“趋势”和“季节”成分。例如，`$(A，M)$` 是具有加性趋势和乘性季节性的方法；
`$(A_{d}，N)$` 是具有衰减趋势且没有季节性的方法等等。

![img](images/ses_class.png)

其中一些方法我们已经知道它们有其他名称：

![img](images/ses_class2.png)

## 新息指数平滑状态空间模型


## 模型估计和选择


## 使用 ETS 模型预测


# AIRMA 模型

ARIMA 模型提供了另一种时间序列预测的方法。
指数平滑模型(exponential smoothing)和 ARIMA 模型是应用最为广泛的两种时间序列预测方法，
基于对这两种预测方法的拓展，很多其他的预测方法得以诞生。
与指数平滑模型针对于数据中的趋势(trend)和季节性(seasonality)不同，
ARIMA 模型旨在描绘数据的自回归性(autocorrelations)。

在引入 ARIMA 模型之前，我们需要先讨论平稳性(stationarity)和差分时间序列(differencing time series)的相关知识。

## 平稳性和差分

### 平稳性

<span style='border-bottom:1.5px dashed red;'>平稳的时间序列的性质不随观测时间的变化而变化。</span> 
因此具有趋势或季节性的时间序列不是平稳时间序列——趋势和季节性使得时间序列在不同时段呈现不同性质。
与它们相反，白噪声序列(white noise series)则是平稳的——不管观测的时间如何变化，
它看起来都应该是一样的。

在判断平稳性上，下面这个例子容易让人混淆：如果一个循环变化的时间序列没有趋势和季节性，
那么它仍然是平稳的。这是因为这些循环变化并没有一个固定的周期，
因此在进行观测之前我们无法知道循环变化的峰值和谷值会出现在哪个位置。

一般而言，一个平稳的时间序列从长期来看不存在可预测的特征。
它的时间曲线图(time plots)反映出这个序列大致保持水平(尽管可能存在一些周期性的变化)并保持固定的方差。

一个分辨平稳时间序列示例：

![img](images/stable.png)

* 显然序列 (d)，(h) 和 (i)因存在季节性因素而被排除
* 序列 (a)，(c)，(e)，(f) 和 (i) 因为存在趋势和变化水平而被排除
* 序列 (i) 由于存在增长的方差被排除
* 只有 (b) 和 (g) 是平稳时间序列

序列 (g) 的循环变化让它第一眼看上去不太平稳，但是这种变化其实是非周期性的——当猞猁的数量超过食物承载的上限时，
它们会停止繁殖从而使得数量回落到非常低的水平，之后食物来源的再生使得猞猁数量重新增长，以此周而复始。
从长期来看，这种循环的时间点是不能预测的，因此序列 (g) 是平稳的。

### 差分

在下图中，我们注意到 (a) 中谷歌股价数并不平稳，但 (b) 中谷歌股价每天的变化量则是平稳的。
这向我们展示了一种让非平稳时间序列变平稳的方法——<span style='border-bottom:1.5px dashed red;'>计算相邻观测值之间的差值</span>，这种方法被称为 <span style='border-bottom:1.5px dashed red;'>差分</span>。

![img](images/ab.png)

诸如 <span style='border-bottom:1.5px dashed red;'>对数变换</span> 的变换方法可用于平稳化时间序列的方差。<span style='border-bottom:1.5px dashed red;'>差分</span>则可以通过去除时间序列中的一些变化特征来平稳化它的均值，
并因此消除（或减小）时间序列的趋势和季节性。

和时间曲线图一样，<span style='border-bottom:1.5px dashed red;'>自相关图（ACF图）</span>也能帮助我们识别非平稳时间序列。对于一个平稳时间序列，
自相关系数（ACF）会快速的下降到接近 0 的水平，然而非平稳时间序列的自相关系数会下降的比较缓慢。
同样的，非平稳时间序列的 `$r_{1}$` 通常非常大且为正值。

![img](images/acf.png)

差分后的谷歌股价的自相关图看起来像白噪声序列。只有一个自相关系数超出了 95% 的限制。

### 随机游走

> * TODO：[随机漫步 Demo](https://wangzhefeng.com/note/2020/05/06/random-walk/)
> * TODO: [随机游走解释](https://wangzhefeng.com/note/2023/03/03/timeseries-stationarity-stochasticity/#%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0)

#### 随机游走模型

差分序列是指原序列的连续观测值之间的变化值组成的时间序列，它可以被表示为：

`$$y'_{t}=y_{t} - y_{t-1}$$`

差分序列的长度只有 `$T-1$` 个，因为第一个观测值 `$y'_{1}$` 的差值无法计算。

当差分序列是白噪声时，原序列的模型可以表示为：

`$$y_{t}-y_{t-1} = \varepsilon_{t}$$`

这里 `$\varepsilon_{t}$` 是白噪声。

调整上式，即可得到”随机游走”模型：

`$$y_{t}=y_{t-1}+\varepsilon_{t}$$`

随机游走模型在非平稳时间序列数据中应用广泛，特别是金融和经济数据。典型的随机游走通常具有以下特征：

* 长期的明显上升或下降趋势
* 游走方向上突然的、不能预测的变化
* 由于未来变化是不可预测的，随机游走模型的预测值为上一次观测值，
  并且其上升和下降的可能性相同。因此，随机游走模型是朴素(naive)预测的基础

#### 带漂移的随机游走模型

通过稍许改进，我们可以让差值均值不为零，从而：

`$$y_{t}-y_{t-1}=c+\varepsilon_{t}$$`

或者

`$$y_{t} = c+ y_{t-1}+\varepsilon_{t}$$`

其中：

* `$c$` 值是连续观测值变化的平均值，如果 `$c$` 值为正，则之前的平均变化情况是增长的，
  因此 `$y_{t}$` 将倾向于继续向上漂移(drift)。反之如果 `$c$` 值为负，`$y_{t}$` 将倾向于向下漂移。

## 二阶差分

有时差分后的数据仍然不平稳，所以可能需要再一次对数据进行差分来得到一个平稳的序列：

`$$\begin{align*}
y^{\prime\prime}_{t}  &=  y^{\prime}_{t} - y^{\prime}_{t - 1} \\
           &= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\
           &= y_t - 2y_{t-1} +y_{t-2}.
\end{align*}$$`

在这种情况下，序列 `$y_{t}$` 的长度为 `$T-2$`。之后我们可以对原数据的”变化的变化”进行建模。
在现实应用中，通常没有必要进行二阶以上的差分。

## 季节性差分

# 动态回归模型

在之前介绍的预测模型中，我们仅利用变量的实际观测值进行建模，
却没有考虑到随时间的推移而产生的相关信息的影响。
例如，假期、竞争对手活动、法律法规变化或其它外部变量影响。
若合理利用此类信息修整模型，可以得到预测效果更好的时间序列模型。
另一方面，在回归模型中，模型考虑了大量预测变量的相关信息，
但并未采用 ARIMA 模型处理时间序列中的动态因素。
在这里，我们考虑如何扩展 ARIMA 模型，将一些与预测变量相关的信息纳入模型之中。

回归模型：

`$$y_{t}=\beta_{0}+\beta_{1}x_{1,t} + \cdots + \beta_{k}x_{k,t} +\varepsilon_{t}$$`

其中：

* `$y_{t}$` 是 `$k$` 个预测变量 `$(x_{1,t}, \cdots, x_{k,t})$` 的线性组合
* `$\varepsilon_{t}$` 是不相关的误差项（例如：误差项为白噪声）
* 可以采用诸如 Breusch-Godfrey 检验之类的检验来评估模型的残差项是否存在显著相关性

这里我们允许误差项中存在自相关。为了与之前的误差项进行区分，我们用 `$\eta_{t}$` 代替 `$\varepsilon_{t}$`。
`$\varepsilon_{t}$` 表示误差项，且利用 ARIMA 模型拟合残差 `$\eta_{t}$`。例如：若残差 `$\eta_{t}$` 满足 `$ARIMA(1, 1, 1)$`，则回归模型可写为：

`$$y_{t} = \beta_{0} + \beta_{1}x_{1, t}+\cdots+\beta_{k}x_{k,t}+\eta_{t}$$`
`$$(1-\phi_{1}B)(1-B)\eta_{t} = (1+\theta_{1}B)\varepsilon_{t}$$`

其中：

* `$\varepsilon_{t}$` 为白噪声

需要注意的是，模型中存在两个残差项：一是来自回归模型的误差，
可用 `$\eta_{t}$` 表示；二是来自 ARIMA 模型的误差，
可用 `$\varepsilon_{t}$` 表示。且假设来自 ARIMA 模型的误差为白噪声。

# 预测分层或分组时间序列



# 高级预测方法




# 实际预测问题












# 参考

* [Forecasting: Principles and Practice](https://otexts.com/fpp3cn/index.html)
